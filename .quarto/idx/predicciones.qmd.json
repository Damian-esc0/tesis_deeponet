{"title":"Predicciones del modelo","markdown":{"yaml":{"title":"Predicciones del modelo","lang":"es","execute":{"freeze":"auto"}},"headingText":"------------------------------------------------------------------------------","containsRefs":false,"markdown":"\n::: {style=\"text-align: justify\"}\nConforme se ha referido previamente, el desarrollo del modelo predictivo se realizó utilizando el framework DeepXDE (versión 1.10.1) con backend de TensorFlow 1.x (configurado mediante tensorflow.compat.v1). Para asegurar reproducibilidad, se fijó la semilla aleatoria en 123 a nivel de DeepXDE, TensorFlow y NumPy. La red neuronal se implementó como un DeepONetCartesianProd con la siguiente estructura especializada:\n\n- Rama (*branch*)\n    - Capa de entrada: (num_sensors + 1)² = 25 neuronas.\n    - 3 capas ocultas de 20 neuronas cada una.\n- Tronco (*trunk*)\n    - Capa de entrada: 3 neuronas (coordenadas espaciotemporales x, y, t).\n    - Misma configuración de capas ocultas que la rama.\n- Hiperparámetros clave\n    - Función de activación: ELU (Exponential Linear Unit).\n    - Inicialización de pesos: Glorot normal.\n    - Optimizador: Adam con tasa de aprendizaje inicial de 2×10⁻³ y decaimiento exponencial (decay_rate=0.05 cada 1000 pasos).\n```{python}\nimport deepxde as dde\nimport numpy as np\nimport tensorflow as tf\n\n# Constants and Parameters\n# ------------------------------------------------------------------------------\n\n# Backend and seed\ndde.backend.set_default_backend(\"tensorflow.compat.v1\")\ndde.config.set_random_seed(123)\n\n# Physical parameters\np = 1050\nc = 3639\nkeff = 5\ntf = 1800\nL0 = 0.05\ncb = 3825\nQ = 0\nTM = 45\nTa = 37\nalpha = p * c / keff\n\n# Dimensionless coefficients\na1 = tf / (alpha * L0**2)\na2 = tf * cb / (p * c)\na3 = (tf * Q) / (p * c * (TM - Ta))\n\n# Domain boundaries\nx_initial, x_boundary = 0.0, 1.0\ny_initial, y_boundary = 0.0, 1.0\nt_initial, t_final = 0.0, 1.0\n\n# Dataset configuration\npts_dom = 10\npts_bc = 25\npts_ic = 55\nnum_test = 25\n\n# Sensor grid and function space\nnum_sensors = 4\nsize_cov_matrix = 40\n\n# Network architecture\nwidth_net = 20\nlen_net = 3\nAF = \"elu\"\nk_initializer = \"Glorot normal\"\n\n# Training parameters\nnum_iterations = 1000\nlearning_rate = 2e-3\ndecay_rate = 0.05\ndecay_steps = 1000\n\n# ------------------------------------------------------------------------------\n# Geometry and Time Domain\n# ------------------------------------------------------------------------------\n\nspatial_domain = dde.geometry.Rectangle([x_initial, y_initial],\n                                        [x_boundary, y_boundary])\ntime_domain = dde.geometry.TimeDomain(t_initial, t_final)\ngeomtime = dde.geometry.GeometryXTime(spatial_domain, time_domain)\n\n# ------------------------------------------------------------------------------\n# PDE and Conditions\n# ------------------------------------------------------------------------------\n\ndef initial_condition(X):\n    return 0\n\ndef heat_equation(func, u, coords):\n    u_t = dde.grad.jacobian(u, func, i=0, j=2)\n    u_xx = dde.grad.hessian(u, func, i=0, j=0)\n    u_yy = dde.grad.hessian(u, func, i=1, j=1)\n    return a1 * u_t - (u_xx + u_yy) + a2 * u\n\ndef zero_value(X):\n    return 0\n\ndef time_value(X):\n    return X[:, 2]\n\ndef is_on_vertex(x):\n    vertices = np.array([[x_initial, y_initial],\n                         [x_boundary, y_initial],\n                         [x_initial, y_boundary],\n                         [x_boundary, y_boundary]])\n    return any(np.allclose(x, v) for v in vertices)\n\ndef is_initial(X, on_initial):\n    return on_initial and np.isclose(X[2], t_initial)\n\ndef left_boundary(X, on_boundary):\n    spatial = X[0:2]\n    t = X[2]\n    return (\n        on_boundary \n        and np.isclose(spatial[0], x_initial) \n        and not np.isclose(t, t_initial) \n        and not is_on_vertex(spatial)\n    )\n\ndef right_boundary(X, on_boundary):\n    spatial = X[0:2]\n    t = X[2]\n    return (\n        on_boundary \n        and np.isclose(spatial[0], x_boundary) \n        and not np.isclose(t, t_initial) \n        and not is_on_vertex(spatial)\n    )\n\ndef up_low_boundary(X, on_boundary):\n    spatial = X[0:2]\n    t = X[2]\n    return (on_boundary \n    and (np.isclose(spatial[1], y_initial) \n    or np.isclose(spatial[1], y_boundary)) \n    and not np.isclose(t, t_initial) \n    and not is_on_vertex(spatial)\n    )\n\n# Initial and boundary conditions\nic = dde.icbc.IC(geomtime, initial_condition, is_initial)\nleft_bc = dde.icbc.DirichletBC(geomtime, \n                                zero_value, left_boundary)\nright_bc = dde.icbc.NeumannBC(geomtime,\n                                time_value, right_boundary)\nup_low_bc = dde.icbc.NeumannBC(geomtime, \n                                zero_value, up_low_boundary)\n\n# ------------------------------------------------------------------------------\n# Dataset Construction\n# ------------------------------------------------------------------------------\n\npde_data = dde.data.TimePDE(\n    geomtime,\n    heat_equation,\n    [ic, left_bc, right_bc, up_low_bc],\n    num_domain=pts_dom,\n    num_boundary=pts_bc,\n    num_initial=pts_ic \n)\n\n# ------------------------------------------------------------------------------\n# Sensor Points and Function Space\n# ------------------------------------------------------------------------------\n\nside = np.linspace(x_initial, x_boundary, num_sensors + 1)\nx, y = np.meshgrid(side, side, indexing='xy')\nsensor_pts = np.stack([x.ravel(), y.ravel()], axis=1)\n\nfs = dde.data.function_spaces.GRF2D(N=size_cov_matrix, \n                                    interp=\"linear\")\n\ndata = dde.data.PDEOperatorCartesianProd(\n    pde_data,\n    fs,\n    sensor_pts,\n    num_function=(num_sensors + 1)**2,\n    function_variables=[0, 1],\n    num_test=num_test\n)\n\n# ------------------------------------------------------------------------------\n# Network Definition\n# ------------------------------------------------------------------------------\n\nbranch_layers = [(num_sensors + 1)**2] + len_net * [width_net]\ntrunk_layers = [3] + len_net * [width_net]\n\nnet = dde.nn.DeepONetCartesianProd(\n    branch_layers,\n    trunk_layers,\n    activation=AF,\n    kernel_initializer=k_initializer\n)\n\n# ------------------------------------------------------------------------------\n# Model Compilation and Training\n# ------------------------------------------------------------------------------\n\nmodel = dde.Model(data, net)\nmodel.compile(\"adam\", lr=learning_rate, decay=(\"inverse time\", decay_steps, decay_rate))\nlosshistory, train_state = model.train(iterations=num_iterations)\n\n# Fine-tuning with LBFGS optimizer\nmodel.compile(\"L-BFGS\")\nlosshistory, train_state = model.train()\n```\n\n## Gráficas de pérdida del modelo\nEl proceso de entrenamiento del modelo se monitoreó mediante el seguimiento detallado de cinco componentes de pérdida, cada una asociada a restricciones físicas y matemáticas específicas del problema:\n\n1. Pérdida residual de la EDP\n    - Función: Mide el cumplimiento de la ecuación de Bio-Calor en el dominio interior.\n    - Importancia: Garantiza que la solución aprendida satisfaga la física subyacente.\n    - Comportamiento esperado: Debe converger a valores cercanos a cero (típicamente < 1e-3).\n\n2. Pérdida de condición inicial\n    - Función: Controla la precisión en t=0.\n    - Importancia: Asegura coherencia con el estado inicial del sistema.\n    - Patrón típico: Suele ser la primera en converger por su carácter puntual.\n\n3. Pérdida de frontera izquierda (Dirichlet)\n    - Función: Evalúa el cumplimiento de condiciones de valor prescrito.\n    - Relevancia: Mantiene valores fijos en bordes específicos.\n    - Convergencia: Normalmente rápida por ser restrictiva.\n\n4. Pérdida de frontera derecha (Neumann)\n    - Función: Verifica gradientes normales en esta frontera\n    - Dificultad característica: Puede mostrar oscilaciones iniciales\n\n5. Pérdida de fronteras superior/inferior (Neumann)\n    - Función: Controla condiciones de flujo en estos bordes\n    - Complejidad: En problemas 2D/3D suele ser la última en estabilizarse\n\n### Perdida para el conjunto de entrenamiento\n```{python}\n#| output: false\n\nimport plotly.graph_objects as go\n\n# Nombres de las componentes del loss\nloss_labels = [\n    \"PDE residual loss\",\n    \"Initial‐condition loss\",\n    \"Left‐boundary (Dirichlet) loss\",\n    \"Right‐boundary (Neumann) loss\",\n    \"Top/Bottom‐boundary (Neumann) loss\"\n]\n\n# Extraer pasos y pérdida de entrenamiento\nsteps = losshistory.steps\ntrain_loss = np.array(losshistory.loss_train)\n\n# Crear figura\nfig_train = go.Figure()\n\nfor i in range(train_loss.shape[1]):\n    fig_train.add_trace(go.Scatter(\n        x=steps,\n        y=train_loss[:, i],\n        mode='lines',\n        name=loss_labels[i]\n    ))\n\nfig_train.update_layout(\n    title=\"Training Loss history\",\n    xaxis=dict(title=\"Iteration\", tickformat=\".1e\"),\n    yaxis=dict(title=\"Loss\", type=\"log\", tickformat=\".1e\"),\n    template=\"plotly_white\",\n    legend=dict(x=0.99, y=0.99),\n    font=dict(size=14)\n)\n```\n\n::: {.content-visible when-format=\"html\"}\n```{python}\n#| label: fig-training_loss\n#| fig-cap: \"Historial de pérdida en el entrenamiento de la red neuronal.\"\n#| echo: false\n\nfig_train.show()\n```\n:::\n\n::: {.content-visible when-format=\"pdf\"}\n```{python}\n#| include: false\nimport numpy as np\nimport os\n# Asegurar que la carpeta 'images' exista\nos.makedirs(\"images\", exist_ok=True)\n# Exportar imagen para PDF\nfig_train.write_image(\"images/fig-training_loss.png\", width=800, height=600)\n```\n\n![Gráfica de la perdida en el entrenamiento.](images/fig-training_loss.png){#fig-loss_training fig-align=\"center\"}\n:::\n\n\n### Pérdida para el conjunto de prueba\n```{python}\n#| output: false\n\nimport plotly.graph_objects as go\n\n# Nombres de las componentes del loss\nloss_labels = [\n    \"PDE residual loss\",\n    \"Initial‐condition loss\",\n    \"Left‐boundary (Dirichlet) loss\",\n    \"Right‐boundary (Neumann) loss\",\n    \"Top/Bottom‐boundary (Neumann) loss\"\n]\n\n# Extraer pasos y pérdida de entrenamiento\nsteps = losshistory.steps\ntest_loss = np.array(losshistory.loss_test)\n\n# Crear figura\nfig_test = go.Figure()\n\nfor i in range(test_loss.shape[1]):\n    fig_test.add_trace(go.Scatter(\n        x=steps,\n        y=test_loss[:, i],\n        mode='lines',\n        name=loss_labels[i]\n    ))\n\nfig_test.update_layout(\n    title=\"Test Loss history\",\n    xaxis=dict(title=\"Iteration\", tickformat=\".1e\"),\n    yaxis=dict(title=\"Loss\", type=\"log\", tickformat=\".1e\"),\n    template=\"plotly_white\",\n    legend=dict(x=0.99, y=0.99),\n    font=dict(size=14)\n)\n```\n\n::: {.content-visible when-format=\"html\"}\n```{python}\n#| label: fig-test_loss\n#| fig-cap: \"Historial de pérdida en el conjunto de prueba de la red neuronal.\"\n#| echo: false\n\nfig_test.show()\n```\n\n:::\n\n::: {.content-visible when-format=\"pdf\"}\n```{python}\n#| include: false\nimport numpy as np\nimport os\n# Asegurar que la carpeta 'images' exista\nos.makedirs(\"images\", exist_ok=True)\n# Exportar imagen para PDF\nfig_test.write_image(\"images/fig-test_loss.png\", width=800, height=600)\n```\n\n![Gráfica de la perdida en el conjunto de prueba.](images/fig-test_loss.png){#fig-loss_test fig-align=\"center\"}\n:::\n\n## Guardado de datos\nPara permitir la comparación cuantitativa con el método de Crank-Nicolson y facilitar la generación de visualizaciones consistentes, se exportaron las predicciones del modelo neuronal en formato CSV. El proceso consistió en:\n\n1. Generación de la malla de evaluación:\n    - Dominio espacial: Cuadrado unitario [0,1] × [0,1].\n    - Discretización: 26 segmentos equiespaciados en cada eje (x, y).\n    - Puntos totales: 676 (26 × 26)\n    - Tiempos evaluados: t = [0.0, 0.25, 0.50, 0.75, 1.0].\n2. Estructura del archivo:\n    - Coordenadas espacio-temporales (t, x, y) para cada punto de la grilla 26×26.\n    - Valores de la solución en los tiempos de interés.\n```{python}\nimport pandas as pd\n# Lista de tiempos\ntimes = [0.0, 0.25, 0.5, 0.75, 1.0]\n\n# Crear la malla (x, y)\nnum_points = 26\nx = np.linspace(0, 1, num_points)\ny = np.linspace(0, 1, num_points)\nX, Y = np.meshgrid(x, y)\n\n# Lista para almacenar resultados\nresults = []\n\nfor t_val in times:\n    # Crear entrada trunk: (num_points^2, 3)\n    points = np.vstack((X.flatten(), Y.flatten(), t_val * np.ones_like(X.flatten()))).T\n\n    # Crear entrada branch: condición inicial constante cero\n    branch_input = np.zeros((1, sensor_pts.shape[0]))\n\n    # Predecir\n    predicted = model.predict((branch_input, points)).flatten()\n\n    # Agregar los datos al resultado\n    for xi, yi, thetai in zip(points[:, 0], points[:, 1], predicted):\n        results.append([t_val, xi, yi, thetai])\n\n# Crear el DataFrame\ndf = pd.DataFrame(results, columns=[\"time\", \"X\", \"Y\", \"Theta\"])\n\n# Obtener la ruta del script actual y guardar el archivo CSV\nruta = r\"data/model_DoN.csv\"\ndf.to_csv(ruta, index=False)\n\n```\n\n::: {.content-visible when-format=\"html\"}\n### Visualización interactiva\nPara facilitar el análisis exploratorio de las predicciones generadas por el modelo DeepONet, se implementó una tabla dinámica interactiva mediante la librería itables (versión 1.5.2), que extiende las funcionalidades de Pandas para su visualización.\n```{python}\n#| label: tbl-data-model\n#| tbl-cap: \"Predicciones de la red neuronal.\"\n#| warning: false\n#| message: false\n\nfrom itables import show, options\n\noptions.maxBytes = 0\n\n# Mostrar la tabla interactiva\nshow(df, paging=True,\n        ordering=True,\n        searching = False,\n        scrollY=\"350px\",\n        buttons=[\"pageLength\", \"csv\", \"excel\"],\n        lengthMenu=[10, 25, 50, 100],\n        classes=\"display nowrap cell-border\"\n        )\n```\n:::\n\n\n## Comparativa visual de las predicciones\nEsta sección presenta un análisis cualitativo de los resultados mediante la comparación directa entre las predicciones del modelo y las soluciones reportadas en el estudio de @medical_rep. La visualización paralela permite evaluar:\n\n- Dominio espacial: Cuadrado unitario [0,1] × [0,1] con malla 26×26.\n- Escala de colores: Mapa térmico viridis (consistente en ambas columnas).\n```{python}\n#| label: fig-my_results\n#| fig-cap: \"Predicciones de la red neuronal a distintos tiempos.\"\n\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\nimport matplotlib.gridspec as gridspec\n\n# Crear una figura y layout con GridSpec\nncols = len(times)\nfig = plt.figure(figsize=((5 * ncols) + 1, 6))\ngs = gridspec.GridSpec(2, ncols, height_ratios=[10, 1], hspace=0.3)\n\n# Lista para almacenar los objetos surface\nsurf_list = []\n\n# Asumimos que el grid es regular, así que podemos inferir la forma\nnum_points = int(np.sqrt(df[df[\"time\"] == times[0]].shape[0]))\n\n# Reordenar para graficar\nfor i, t_val in enumerate(times):\n    # Filtrar por tiempo actual\n    df_t = df[df[\"time\"] == t_val]\n\n    # Obtener los valores de X, Y, Theta\n    X_vals = df_t[\"X\"].values.reshape((num_points, num_points))\n    Y_vals = df_t[\"Y\"].values.reshape((num_points, num_points))\n    Z_vals = df_t[\"Theta\"].values.reshape((num_points, num_points))\n\n    # Subgráfico 3D\n    ax = fig.add_subplot(gs[0, i], projection=\"3d\")\n\n    # Dibujar la superficie\n    surf = ax.plot_surface(\n        Y_vals, X_vals, Z_vals,\n        rstride=1, cstride=1,\n        cmap=\"YlGnBu\",\n        edgecolor=\"none\",\n        antialiased=True\n    )\n    surf_list.append(surf)\n\n    ax.set_title(f\"Time = {t_val:.2f} s\")\n    ax.set_xlabel(\"Y\")\n    ax.set_ylabel(\"X\")\n    ax.set_zlabel(\"T[K]\", labelpad=5, rotation=90)\n\n# Barra de color común\ncbar_ax = fig.add_subplot(gs[1, :])\nfig.colorbar(surf_list[-1], cax=cbar_ax, orientation=\"horizontal\")\n\nplt.show()\n```\n\n\n![Resultados reportados por @medical_rep en el caso 2D.](images/results_paper.png){#fig-results_fnn fig-align=\"center\" width=\"550\"}\n:::\n\n## Validación Cuantitativa frente al Método de Crank-Nicolson\nPara evaluar numéricamente la precisión del modelo DeepONet, se realizó una comparación sistemática con soluciones de referencia generadas mediante el método de Crank-Nicolson. Este enfoque proporciona una métrica objetiva de la exactitud del modelo, más allá de la inspección visual.\n\n```{python}\nimport os\n\n# Definir los tiempos a evaluar\ntimes = [0.0, 0.25, 0.5, 0.75, 1.0]\n\n# Rutas de los archivos (modificar según sea necesario)\ncrank_nick_path = \"data/crank_nick.csv\"\nmodel_don_path = \"data/model_DoN.csv\"\noutput_path = \"data/error_comparison.csv\"\n\n# Cargar los datos\ndef load_data(file_path):\n    try:\n        return pd.read_csv(file_path)\n    except FileNotFoundError:\n        print(f\"Error: No se encontró el archivo {file_path}\")\n        return None\n    except Exception as e:\n        print(f\"Error al cargar {file_path}: {str(e)}\")\n        return None\n\ncrank_nick_data = load_data(crank_nick_path)\nmodel_don_data = load_data(model_don_path)\n\nif crank_nick_data is None or model_don_data is None:\n    exit()\n\n# Función para calcular errores\ndef calculate_errors(true_data, pred_data, times):\n    results = []\n    \n    for time in times:\n        # Filtrar datos por tiempo\n        true_subset = true_data[true_data['time'] == time]\n        pred_subset = pred_data[pred_data['time'] == time]\n        \n        if len(true_subset) == 0 or len(pred_subset) == 0:\n            print(f\"Advertencia: No hay datos para tiempo t={time}\")\n            continue\n        \n        # Verificar que las dimensiones coincidan\n        if len(true_subset) != len(pred_subset):\n            print(f\"Advertencia: Número de puntos no coincide para t={time}\")\n            min_len = min(len(true_subset), len(pred_subset))\n            true_subset = true_subset.iloc[:min_len]\n            pred_subset = pred_subset.iloc[:min_len]\n        \n        # Calcular errores para Theta\n        theta_true = true_subset['Theta'].values\n        theta_pred = pred_subset['Theta'].values\n        \n        absolute_error = np.abs(theta_true - theta_pred)\n        l2_error = np.sqrt(np.sum((theta_true - theta_pred)**2))\n        \n        results.append({\n            'time': time,\n            'mean_absolute_error': np.mean(absolute_error),\n            'max_absolute_error': np.max(absolute_error),\n            'l2_error': l2_error\n        })\n    \n    return pd.DataFrame(results)\n\n# Calcular errores\nerror_results = calculate_errors(crank_nick_data, model_don_data, times)\n\n# Guardar resultados\nerror_results.to_csv(output_path, index=False)\n```\n\n\n```{python}\n#| label: tbl-errores\n#| tbl-cap: \"Error del modelo DeepONet respecto a Crank-Nicolson.\"\n#| echo: false\nfrom tabulate import tabulate\n\n# Convertir a formato markdown para mejor visualización\nerror_table = tabulate(\n    error_results,\n    headers=['Tiempo', 'MAE', 'MaxAE', 'Error'],\n    tablefmt='pipe',\n    floatfmt=\".3f\",\n    showindex=False\n)\nprint(error_table)\n```","srcMarkdownNoYaml":"\n::: {style=\"text-align: justify\"}\nConforme se ha referido previamente, el desarrollo del modelo predictivo se realizó utilizando el framework DeepXDE (versión 1.10.1) con backend de TensorFlow 1.x (configurado mediante tensorflow.compat.v1). Para asegurar reproducibilidad, se fijó la semilla aleatoria en 123 a nivel de DeepXDE, TensorFlow y NumPy. La red neuronal se implementó como un DeepONetCartesianProd con la siguiente estructura especializada:\n\n- Rama (*branch*)\n    - Capa de entrada: (num_sensors + 1)² = 25 neuronas.\n    - 3 capas ocultas de 20 neuronas cada una.\n- Tronco (*trunk*)\n    - Capa de entrada: 3 neuronas (coordenadas espaciotemporales x, y, t).\n    - Misma configuración de capas ocultas que la rama.\n- Hiperparámetros clave\n    - Función de activación: ELU (Exponential Linear Unit).\n    - Inicialización de pesos: Glorot normal.\n    - Optimizador: Adam con tasa de aprendizaje inicial de 2×10⁻³ y decaimiento exponencial (decay_rate=0.05 cada 1000 pasos).\n```{python}\nimport deepxde as dde\nimport numpy as np\nimport tensorflow as tf\n\n# ------------------------------------------------------------------------------\n# Constants and Parameters\n# ------------------------------------------------------------------------------\n\n# Backend and seed\ndde.backend.set_default_backend(\"tensorflow.compat.v1\")\ndde.config.set_random_seed(123)\n\n# Physical parameters\np = 1050\nc = 3639\nkeff = 5\ntf = 1800\nL0 = 0.05\ncb = 3825\nQ = 0\nTM = 45\nTa = 37\nalpha = p * c / keff\n\n# Dimensionless coefficients\na1 = tf / (alpha * L0**2)\na2 = tf * cb / (p * c)\na3 = (tf * Q) / (p * c * (TM - Ta))\n\n# Domain boundaries\nx_initial, x_boundary = 0.0, 1.0\ny_initial, y_boundary = 0.0, 1.0\nt_initial, t_final = 0.0, 1.0\n\n# Dataset configuration\npts_dom = 10\npts_bc = 25\npts_ic = 55\nnum_test = 25\n\n# Sensor grid and function space\nnum_sensors = 4\nsize_cov_matrix = 40\n\n# Network architecture\nwidth_net = 20\nlen_net = 3\nAF = \"elu\"\nk_initializer = \"Glorot normal\"\n\n# Training parameters\nnum_iterations = 1000\nlearning_rate = 2e-3\ndecay_rate = 0.05\ndecay_steps = 1000\n\n# ------------------------------------------------------------------------------\n# Geometry and Time Domain\n# ------------------------------------------------------------------------------\n\nspatial_domain = dde.geometry.Rectangle([x_initial, y_initial],\n                                        [x_boundary, y_boundary])\ntime_domain = dde.geometry.TimeDomain(t_initial, t_final)\ngeomtime = dde.geometry.GeometryXTime(spatial_domain, time_domain)\n\n# ------------------------------------------------------------------------------\n# PDE and Conditions\n# ------------------------------------------------------------------------------\n\ndef initial_condition(X):\n    return 0\n\ndef heat_equation(func, u, coords):\n    u_t = dde.grad.jacobian(u, func, i=0, j=2)\n    u_xx = dde.grad.hessian(u, func, i=0, j=0)\n    u_yy = dde.grad.hessian(u, func, i=1, j=1)\n    return a1 * u_t - (u_xx + u_yy) + a2 * u\n\ndef zero_value(X):\n    return 0\n\ndef time_value(X):\n    return X[:, 2]\n\ndef is_on_vertex(x):\n    vertices = np.array([[x_initial, y_initial],\n                         [x_boundary, y_initial],\n                         [x_initial, y_boundary],\n                         [x_boundary, y_boundary]])\n    return any(np.allclose(x, v) for v in vertices)\n\ndef is_initial(X, on_initial):\n    return on_initial and np.isclose(X[2], t_initial)\n\ndef left_boundary(X, on_boundary):\n    spatial = X[0:2]\n    t = X[2]\n    return (\n        on_boundary \n        and np.isclose(spatial[0], x_initial) \n        and not np.isclose(t, t_initial) \n        and not is_on_vertex(spatial)\n    )\n\ndef right_boundary(X, on_boundary):\n    spatial = X[0:2]\n    t = X[2]\n    return (\n        on_boundary \n        and np.isclose(spatial[0], x_boundary) \n        and not np.isclose(t, t_initial) \n        and not is_on_vertex(spatial)\n    )\n\ndef up_low_boundary(X, on_boundary):\n    spatial = X[0:2]\n    t = X[2]\n    return (on_boundary \n    and (np.isclose(spatial[1], y_initial) \n    or np.isclose(spatial[1], y_boundary)) \n    and not np.isclose(t, t_initial) \n    and not is_on_vertex(spatial)\n    )\n\n# Initial and boundary conditions\nic = dde.icbc.IC(geomtime, initial_condition, is_initial)\nleft_bc = dde.icbc.DirichletBC(geomtime, \n                                zero_value, left_boundary)\nright_bc = dde.icbc.NeumannBC(geomtime,\n                                time_value, right_boundary)\nup_low_bc = dde.icbc.NeumannBC(geomtime, \n                                zero_value, up_low_boundary)\n\n# ------------------------------------------------------------------------------\n# Dataset Construction\n# ------------------------------------------------------------------------------\n\npde_data = dde.data.TimePDE(\n    geomtime,\n    heat_equation,\n    [ic, left_bc, right_bc, up_low_bc],\n    num_domain=pts_dom,\n    num_boundary=pts_bc,\n    num_initial=pts_ic \n)\n\n# ------------------------------------------------------------------------------\n# Sensor Points and Function Space\n# ------------------------------------------------------------------------------\n\nside = np.linspace(x_initial, x_boundary, num_sensors + 1)\nx, y = np.meshgrid(side, side, indexing='xy')\nsensor_pts = np.stack([x.ravel(), y.ravel()], axis=1)\n\nfs = dde.data.function_spaces.GRF2D(N=size_cov_matrix, \n                                    interp=\"linear\")\n\ndata = dde.data.PDEOperatorCartesianProd(\n    pde_data,\n    fs,\n    sensor_pts,\n    num_function=(num_sensors + 1)**2,\n    function_variables=[0, 1],\n    num_test=num_test\n)\n\n# ------------------------------------------------------------------------------\n# Network Definition\n# ------------------------------------------------------------------------------\n\nbranch_layers = [(num_sensors + 1)**2] + len_net * [width_net]\ntrunk_layers = [3] + len_net * [width_net]\n\nnet = dde.nn.DeepONetCartesianProd(\n    branch_layers,\n    trunk_layers,\n    activation=AF,\n    kernel_initializer=k_initializer\n)\n\n# ------------------------------------------------------------------------------\n# Model Compilation and Training\n# ------------------------------------------------------------------------------\n\nmodel = dde.Model(data, net)\nmodel.compile(\"adam\", lr=learning_rate, decay=(\"inverse time\", decay_steps, decay_rate))\nlosshistory, train_state = model.train(iterations=num_iterations)\n\n# Fine-tuning with LBFGS optimizer\nmodel.compile(\"L-BFGS\")\nlosshistory, train_state = model.train()\n```\n\n## Gráficas de pérdida del modelo\nEl proceso de entrenamiento del modelo se monitoreó mediante el seguimiento detallado de cinco componentes de pérdida, cada una asociada a restricciones físicas y matemáticas específicas del problema:\n\n1. Pérdida residual de la EDP\n    - Función: Mide el cumplimiento de la ecuación de Bio-Calor en el dominio interior.\n    - Importancia: Garantiza que la solución aprendida satisfaga la física subyacente.\n    - Comportamiento esperado: Debe converger a valores cercanos a cero (típicamente < 1e-3).\n\n2. Pérdida de condición inicial\n    - Función: Controla la precisión en t=0.\n    - Importancia: Asegura coherencia con el estado inicial del sistema.\n    - Patrón típico: Suele ser la primera en converger por su carácter puntual.\n\n3. Pérdida de frontera izquierda (Dirichlet)\n    - Función: Evalúa el cumplimiento de condiciones de valor prescrito.\n    - Relevancia: Mantiene valores fijos en bordes específicos.\n    - Convergencia: Normalmente rápida por ser restrictiva.\n\n4. Pérdida de frontera derecha (Neumann)\n    - Función: Verifica gradientes normales en esta frontera\n    - Dificultad característica: Puede mostrar oscilaciones iniciales\n\n5. Pérdida de fronteras superior/inferior (Neumann)\n    - Función: Controla condiciones de flujo en estos bordes\n    - Complejidad: En problemas 2D/3D suele ser la última en estabilizarse\n\n### Perdida para el conjunto de entrenamiento\n```{python}\n#| output: false\n\nimport plotly.graph_objects as go\n\n# Nombres de las componentes del loss\nloss_labels = [\n    \"PDE residual loss\",\n    \"Initial‐condition loss\",\n    \"Left‐boundary (Dirichlet) loss\",\n    \"Right‐boundary (Neumann) loss\",\n    \"Top/Bottom‐boundary (Neumann) loss\"\n]\n\n# Extraer pasos y pérdida de entrenamiento\nsteps = losshistory.steps\ntrain_loss = np.array(losshistory.loss_train)\n\n# Crear figura\nfig_train = go.Figure()\n\nfor i in range(train_loss.shape[1]):\n    fig_train.add_trace(go.Scatter(\n        x=steps,\n        y=train_loss[:, i],\n        mode='lines',\n        name=loss_labels[i]\n    ))\n\nfig_train.update_layout(\n    title=\"Training Loss history\",\n    xaxis=dict(title=\"Iteration\", tickformat=\".1e\"),\n    yaxis=dict(title=\"Loss\", type=\"log\", tickformat=\".1e\"),\n    template=\"plotly_white\",\n    legend=dict(x=0.99, y=0.99),\n    font=dict(size=14)\n)\n```\n\n::: {.content-visible when-format=\"html\"}\n```{python}\n#| label: fig-training_loss\n#| fig-cap: \"Historial de pérdida en el entrenamiento de la red neuronal.\"\n#| echo: false\n\nfig_train.show()\n```\n:::\n\n::: {.content-visible when-format=\"pdf\"}\n```{python}\n#| include: false\nimport numpy as np\nimport os\n# Asegurar que la carpeta 'images' exista\nos.makedirs(\"images\", exist_ok=True)\n# Exportar imagen para PDF\nfig_train.write_image(\"images/fig-training_loss.png\", width=800, height=600)\n```\n\n![Gráfica de la perdida en el entrenamiento.](images/fig-training_loss.png){#fig-loss_training fig-align=\"center\"}\n:::\n\n\n### Pérdida para el conjunto de prueba\n```{python}\n#| output: false\n\nimport plotly.graph_objects as go\n\n# Nombres de las componentes del loss\nloss_labels = [\n    \"PDE residual loss\",\n    \"Initial‐condition loss\",\n    \"Left‐boundary (Dirichlet) loss\",\n    \"Right‐boundary (Neumann) loss\",\n    \"Top/Bottom‐boundary (Neumann) loss\"\n]\n\n# Extraer pasos y pérdida de entrenamiento\nsteps = losshistory.steps\ntest_loss = np.array(losshistory.loss_test)\n\n# Crear figura\nfig_test = go.Figure()\n\nfor i in range(test_loss.shape[1]):\n    fig_test.add_trace(go.Scatter(\n        x=steps,\n        y=test_loss[:, i],\n        mode='lines',\n        name=loss_labels[i]\n    ))\n\nfig_test.update_layout(\n    title=\"Test Loss history\",\n    xaxis=dict(title=\"Iteration\", tickformat=\".1e\"),\n    yaxis=dict(title=\"Loss\", type=\"log\", tickformat=\".1e\"),\n    template=\"plotly_white\",\n    legend=dict(x=0.99, y=0.99),\n    font=dict(size=14)\n)\n```\n\n::: {.content-visible when-format=\"html\"}\n```{python}\n#| label: fig-test_loss\n#| fig-cap: \"Historial de pérdida en el conjunto de prueba de la red neuronal.\"\n#| echo: false\n\nfig_test.show()\n```\n\n:::\n\n::: {.content-visible when-format=\"pdf\"}\n```{python}\n#| include: false\nimport numpy as np\nimport os\n# Asegurar que la carpeta 'images' exista\nos.makedirs(\"images\", exist_ok=True)\n# Exportar imagen para PDF\nfig_test.write_image(\"images/fig-test_loss.png\", width=800, height=600)\n```\n\n![Gráfica de la perdida en el conjunto de prueba.](images/fig-test_loss.png){#fig-loss_test fig-align=\"center\"}\n:::\n\n## Guardado de datos\nPara permitir la comparación cuantitativa con el método de Crank-Nicolson y facilitar la generación de visualizaciones consistentes, se exportaron las predicciones del modelo neuronal en formato CSV. El proceso consistió en:\n\n1. Generación de la malla de evaluación:\n    - Dominio espacial: Cuadrado unitario [0,1] × [0,1].\n    - Discretización: 26 segmentos equiespaciados en cada eje (x, y).\n    - Puntos totales: 676 (26 × 26)\n    - Tiempos evaluados: t = [0.0, 0.25, 0.50, 0.75, 1.0].\n2. Estructura del archivo:\n    - Coordenadas espacio-temporales (t, x, y) para cada punto de la grilla 26×26.\n    - Valores de la solución en los tiempos de interés.\n```{python}\nimport pandas as pd\n# Lista de tiempos\ntimes = [0.0, 0.25, 0.5, 0.75, 1.0]\n\n# Crear la malla (x, y)\nnum_points = 26\nx = np.linspace(0, 1, num_points)\ny = np.linspace(0, 1, num_points)\nX, Y = np.meshgrid(x, y)\n\n# Lista para almacenar resultados\nresults = []\n\nfor t_val in times:\n    # Crear entrada trunk: (num_points^2, 3)\n    points = np.vstack((X.flatten(), Y.flatten(), t_val * np.ones_like(X.flatten()))).T\n\n    # Crear entrada branch: condición inicial constante cero\n    branch_input = np.zeros((1, sensor_pts.shape[0]))\n\n    # Predecir\n    predicted = model.predict((branch_input, points)).flatten()\n\n    # Agregar los datos al resultado\n    for xi, yi, thetai in zip(points[:, 0], points[:, 1], predicted):\n        results.append([t_val, xi, yi, thetai])\n\n# Crear el DataFrame\ndf = pd.DataFrame(results, columns=[\"time\", \"X\", \"Y\", \"Theta\"])\n\n# Obtener la ruta del script actual y guardar el archivo CSV\nruta = r\"data/model_DoN.csv\"\ndf.to_csv(ruta, index=False)\n\n```\n\n::: {.content-visible when-format=\"html\"}\n### Visualización interactiva\nPara facilitar el análisis exploratorio de las predicciones generadas por el modelo DeepONet, se implementó una tabla dinámica interactiva mediante la librería itables (versión 1.5.2), que extiende las funcionalidades de Pandas para su visualización.\n```{python}\n#| label: tbl-data-model\n#| tbl-cap: \"Predicciones de la red neuronal.\"\n#| warning: false\n#| message: false\n\nfrom itables import show, options\n\noptions.maxBytes = 0\n\n# Mostrar la tabla interactiva\nshow(df, paging=True,\n        ordering=True,\n        searching = False,\n        scrollY=\"350px\",\n        buttons=[\"pageLength\", \"csv\", \"excel\"],\n        lengthMenu=[10, 25, 50, 100],\n        classes=\"display nowrap cell-border\"\n        )\n```\n:::\n\n\n## Comparativa visual de las predicciones\nEsta sección presenta un análisis cualitativo de los resultados mediante la comparación directa entre las predicciones del modelo y las soluciones reportadas en el estudio de @medical_rep. La visualización paralela permite evaluar:\n\n- Dominio espacial: Cuadrado unitario [0,1] × [0,1] con malla 26×26.\n- Escala de colores: Mapa térmico viridis (consistente en ambas columnas).\n```{python}\n#| label: fig-my_results\n#| fig-cap: \"Predicciones de la red neuronal a distintos tiempos.\"\n\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\nimport matplotlib.gridspec as gridspec\n\n# Crear una figura y layout con GridSpec\nncols = len(times)\nfig = plt.figure(figsize=((5 * ncols) + 1, 6))\ngs = gridspec.GridSpec(2, ncols, height_ratios=[10, 1], hspace=0.3)\n\n# Lista para almacenar los objetos surface\nsurf_list = []\n\n# Asumimos que el grid es regular, así que podemos inferir la forma\nnum_points = int(np.sqrt(df[df[\"time\"] == times[0]].shape[0]))\n\n# Reordenar para graficar\nfor i, t_val in enumerate(times):\n    # Filtrar por tiempo actual\n    df_t = df[df[\"time\"] == t_val]\n\n    # Obtener los valores de X, Y, Theta\n    X_vals = df_t[\"X\"].values.reshape((num_points, num_points))\n    Y_vals = df_t[\"Y\"].values.reshape((num_points, num_points))\n    Z_vals = df_t[\"Theta\"].values.reshape((num_points, num_points))\n\n    # Subgráfico 3D\n    ax = fig.add_subplot(gs[0, i], projection=\"3d\")\n\n    # Dibujar la superficie\n    surf = ax.plot_surface(\n        Y_vals, X_vals, Z_vals,\n        rstride=1, cstride=1,\n        cmap=\"YlGnBu\",\n        edgecolor=\"none\",\n        antialiased=True\n    )\n    surf_list.append(surf)\n\n    ax.set_title(f\"Time = {t_val:.2f} s\")\n    ax.set_xlabel(\"Y\")\n    ax.set_ylabel(\"X\")\n    ax.set_zlabel(\"T[K]\", labelpad=5, rotation=90)\n\n# Barra de color común\ncbar_ax = fig.add_subplot(gs[1, :])\nfig.colorbar(surf_list[-1], cax=cbar_ax, orientation=\"horizontal\")\n\nplt.show()\n```\n\n\n![Resultados reportados por @medical_rep en el caso 2D.](images/results_paper.png){#fig-results_fnn fig-align=\"center\" width=\"550\"}\n:::\n\n## Validación Cuantitativa frente al Método de Crank-Nicolson\nPara evaluar numéricamente la precisión del modelo DeepONet, se realizó una comparación sistemática con soluciones de referencia generadas mediante el método de Crank-Nicolson. Este enfoque proporciona una métrica objetiva de la exactitud del modelo, más allá de la inspección visual.\n\n```{python}\nimport os\n\n# Definir los tiempos a evaluar\ntimes = [0.0, 0.25, 0.5, 0.75, 1.0]\n\n# Rutas de los archivos (modificar según sea necesario)\ncrank_nick_path = \"data/crank_nick.csv\"\nmodel_don_path = \"data/model_DoN.csv\"\noutput_path = \"data/error_comparison.csv\"\n\n# Cargar los datos\ndef load_data(file_path):\n    try:\n        return pd.read_csv(file_path)\n    except FileNotFoundError:\n        print(f\"Error: No se encontró el archivo {file_path}\")\n        return None\n    except Exception as e:\n        print(f\"Error al cargar {file_path}: {str(e)}\")\n        return None\n\ncrank_nick_data = load_data(crank_nick_path)\nmodel_don_data = load_data(model_don_path)\n\nif crank_nick_data is None or model_don_data is None:\n    exit()\n\n# Función para calcular errores\ndef calculate_errors(true_data, pred_data, times):\n    results = []\n    \n    for time in times:\n        # Filtrar datos por tiempo\n        true_subset = true_data[true_data['time'] == time]\n        pred_subset = pred_data[pred_data['time'] == time]\n        \n        if len(true_subset) == 0 or len(pred_subset) == 0:\n            print(f\"Advertencia: No hay datos para tiempo t={time}\")\n            continue\n        \n        # Verificar que las dimensiones coincidan\n        if len(true_subset) != len(pred_subset):\n            print(f\"Advertencia: Número de puntos no coincide para t={time}\")\n            min_len = min(len(true_subset), len(pred_subset))\n            true_subset = true_subset.iloc[:min_len]\n            pred_subset = pred_subset.iloc[:min_len]\n        \n        # Calcular errores para Theta\n        theta_true = true_subset['Theta'].values\n        theta_pred = pred_subset['Theta'].values\n        \n        absolute_error = np.abs(theta_true - theta_pred)\n        l2_error = np.sqrt(np.sum((theta_true - theta_pred)**2))\n        \n        results.append({\n            'time': time,\n            'mean_absolute_error': np.mean(absolute_error),\n            'max_absolute_error': np.max(absolute_error),\n            'l2_error': l2_error\n        })\n    \n    return pd.DataFrame(results)\n\n# Calcular errores\nerror_results = calculate_errors(crank_nick_data, model_don_data, times)\n\n# Guardar resultados\nerror_results.to_csv(output_path, index=False)\n```\n\n\n```{python}\n#| label: tbl-errores\n#| tbl-cap: \"Error del modelo DeepONet respecto a Crank-Nicolson.\"\n#| echo: false\nfrom tabulate import tabulate\n\n# Convertir a formato markdown para mejor visualización\nerror_table = tabulate(\n    error_results,\n    headers=['Tiempo', 'MAE', 'MaxAE', 'Error'],\n    tablefmt='pipe',\n    floatfmt=\".3f\",\n    showindex=False\n)\nprint(error_table)\n```"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":"auto","echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"jupyter"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":true,"code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","highlight-style":"a11y","html-math-method":"mathjax","output-file":"predicciones.html"},"language":{"toc-title-document":"Tabla de contenidos","toc-title-website":"En esta página","related-formats-title":"Otros formatos","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Fuente","other-links-title":"Otros Enlaces","code-links-title":"Enlaces de código","launch-dev-container-title":"Iniciar Dev Container","launch-binder-title":"Iniciar Binder","article-notebook-label":"Cuaderno de Artículo","notebook-preview-download":"Descargar Cuaderno","notebook-preview-download-src":"Descargar código fuente","notebook-preview-back":"Volver al Artículo","manuscript-meca-bundle":"Archivo MECA","section-title-abstract":"Resumen","section-title-appendices":"Apéndices","section-title-footnotes":"Notas","section-title-references":"Referencias","section-title-reuse":"Reutilización","section-title-copyright":"Derechos de autor","section-title-citation":"Cómo citar","appendix-attribution-cite-as":"Por favor, cita este trabajo como:","appendix-attribution-bibtex":"BibTeX","appendix-view-license":"Ver Licencia","title-block-author-single":"Autor/a","title-block-author-plural":"Autores/as","title-block-affiliation-single":"Afiliación","title-block-affiliation-plural":"Afiliaciones","title-block-published":"Fecha de publicación","title-block-modified":"Fecha de modificación","title-block-keywords":"Palabras clave","callout-tip-title":"Tip","callout-note-title":"Nota","callout-warning-title":"Advertencia","callout-important-title":"Importante","callout-caution-title":"Precaución","code-summary":"Código","code-tools-menu-caption":"Código","code-tools-show-all-code":"Mostrar todo el código","code-tools-hide-all-code":"Ocultar todo el código","code-tools-view-source":"Ver el código fuente","code-tools-source-code":"Ejecutar el código","tools-share":"Compartir","tools-download":"Descargar","code-line":"Línea","code-lines":"Líneas","copy-button-tooltip":"Copiar al portapapeles","copy-button-tooltip-success":"Copiado","repo-action-links-edit":"Editar esta página","repo-action-links-source":"Ver el código","repo-action-links-issue":"Informar de un problema","back-to-top":"Volver arriba","search-no-results-text":"Sin resultados","search-matching-documents-text":"documentos encontrados","search-copy-link-title":"Copiar el enlace en la búsqueda","search-hide-matches-text":"Ocultar resultados adicionales","search-more-match-text":"resultado adicional en este documento","search-more-matches-text":"resultados adicionales en este documento","search-clear-button-title":"Borrar","search-text-placeholder":"","search-detached-cancel-button-title":"Cancelar","search-submit-button-title":"Enviar","search-label":"Buscar","toggle-section":"Alternar sección","toggle-sidebar":"Alternar barra lateral","toggle-dark-mode":"Alternar modo oscuro","toggle-reader-mode":"Alternar modo lector","toggle-navigation":"Navegación de palanca","crossref-fig-title":"Figura","crossref-tbl-title":"Tabla","crossref-lst-title":"Listado","crossref-thm-title":"Teorema","crossref-lem-title":"Lema","crossref-cor-title":"Corolario","crossref-prp-title":"Proposición","crossref-cnj-title":"Conjetura","crossref-def-title":"Definición","crossref-exm-title":"Ejemplo","crossref-exr-title":"Ejercicio","crossref-ch-prefix":"Capítulo","crossref-apx-prefix":"Apéndice","crossref-sec-prefix":"Sección","crossref-eq-prefix":"Ecuación","crossref-lof-title":"Listado de Figuras","crossref-lot-title":"Listado de Tablas","crossref-lol-title":"Listado de Listados","environment-proof-title":"Prueba","environment-remark-title":"Observación","environment-solution-title":"Solución","listing-page-order-by":"Ordenar por","listing-page-order-by-default":"Por defecto","listing-page-order-by-date-asc":"Menos reciente","listing-page-order-by-date-desc":"Más reciente","listing-page-order-by-number-desc":"De mayor a menor","listing-page-order-by-number-asc":"De menor a mayor","listing-page-field-date":"Fecha","listing-page-field-title":"Título","listing-page-field-description":"Descripción","listing-page-field-author":"Autor/a","listing-page-field-filename":"Nombre de archivo","listing-page-field-filemodified":"Fecha de modificación","listing-page-field-subtitle":"Subtítulo","listing-page-field-readingtime":"Tiempo de lectura","listing-page-field-wordcount":"Conteo de Palabras","listing-page-field-categories":"Categorías","listing-page-minutes-compact":"{0} minutos","listing-page-category-all":"Todas","listing-page-no-matches":"No hay resultados","listing-page-words":"{0} palabras","listing-page-filter":"Filtro","draft":"Borrador"},"metadata":{"lang":"es","fig-responsive":true,"quarto-version":"1.7.22","bibliography":["references.bib"],"theme":{"light":"cosmo","dark":"darkly"},"grid":{"sidebar-width":"300px","body-width":"950px","margin-width":"250px","gutter-width":"1.5rem"},"code-copy":true,"title":"Predicciones del modelo"},"extensions":{"book":{"multiFile":true}}},"pdf":{"identifier":{"display-name":"PDF","target-format":"pdf","base-format":"pdf"},"execute":{"fig-width":5.5,"fig-height":3.5,"fig-format":"pdf","fig-dpi":300,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":"auto","echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"jupyter"},"render":{"keep-tex":true,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"pdf","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":true,"merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"pdf-engine":"lualatex","standalone":true,"variables":{"graphics":true,"tables":true},"default-image-extension":"pdf","to":"pdf","output-file":"predicciones.pdf"},"language":{"toc-title-document":"Tabla de contenidos","toc-title-website":"En esta página","related-formats-title":"Otros formatos","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Fuente","other-links-title":"Otros Enlaces","code-links-title":"Enlaces de código","launch-dev-container-title":"Iniciar Dev Container","launch-binder-title":"Iniciar Binder","article-notebook-label":"Cuaderno de Artículo","notebook-preview-download":"Descargar Cuaderno","notebook-preview-download-src":"Descargar código fuente","notebook-preview-back":"Volver al Artículo","manuscript-meca-bundle":"Archivo MECA","section-title-abstract":"Resumen","section-title-appendices":"Apéndices","section-title-footnotes":"Notas","section-title-references":"Referencias","section-title-reuse":"Reutilización","section-title-copyright":"Derechos de autor","section-title-citation":"Cómo citar","appendix-attribution-cite-as":"Por favor, cita este trabajo como:","appendix-attribution-bibtex":"BibTeX","appendix-view-license":"Ver Licencia","title-block-author-single":"Autor/a","title-block-author-plural":"Autores/as","title-block-affiliation-single":"Afiliación","title-block-affiliation-plural":"Afiliaciones","title-block-published":"Fecha de publicación","title-block-modified":"Fecha de modificación","title-block-keywords":"Palabras clave","callout-tip-title":"Tip","callout-note-title":"Nota","callout-warning-title":"Advertencia","callout-important-title":"Importante","callout-caution-title":"Precaución","code-summary":"Código","code-tools-menu-caption":"Código","code-tools-show-all-code":"Mostrar todo el código","code-tools-hide-all-code":"Ocultar todo el código","code-tools-view-source":"Ver el código fuente","code-tools-source-code":"Ejecutar el código","tools-share":"Compartir","tools-download":"Descargar","code-line":"Línea","code-lines":"Líneas","copy-button-tooltip":"Copiar al portapapeles","copy-button-tooltip-success":"Copiado","repo-action-links-edit":"Editar esta página","repo-action-links-source":"Ver el código","repo-action-links-issue":"Informar de un problema","back-to-top":"Volver arriba","search-no-results-text":"Sin resultados","search-matching-documents-text":"documentos encontrados","search-copy-link-title":"Copiar el enlace en la búsqueda","search-hide-matches-text":"Ocultar resultados adicionales","search-more-match-text":"resultado adicional en este documento","search-more-matches-text":"resultados adicionales en este documento","search-clear-button-title":"Borrar","search-text-placeholder":"","search-detached-cancel-button-title":"Cancelar","search-submit-button-title":"Enviar","search-label":"Buscar","toggle-section":"Alternar sección","toggle-sidebar":"Alternar barra lateral","toggle-dark-mode":"Alternar modo oscuro","toggle-reader-mode":"Alternar modo lector","toggle-navigation":"Navegación de palanca","crossref-fig-title":"Figura","crossref-tbl-title":"Tabla","crossref-lst-title":"Listado","crossref-thm-title":"Teorema","crossref-lem-title":"Lema","crossref-cor-title":"Corolario","crossref-prp-title":"Proposición","crossref-cnj-title":"Conjetura","crossref-def-title":"Definición","crossref-exm-title":"Ejemplo","crossref-exr-title":"Ejercicio","crossref-ch-prefix":"Capítulo","crossref-apx-prefix":"Apéndice","crossref-sec-prefix":"Sección","crossref-eq-prefix":"Ecuación","crossref-lof-title":"Listado de Figuras","crossref-lot-title":"Listado de Tablas","crossref-lol-title":"Listado de Listados","environment-proof-title":"Prueba","environment-remark-title":"Observación","environment-solution-title":"Solución","listing-page-order-by":"Ordenar por","listing-page-order-by-default":"Por defecto","listing-page-order-by-date-asc":"Menos reciente","listing-page-order-by-date-desc":"Más reciente","listing-page-order-by-number-desc":"De mayor a menor","listing-page-order-by-number-asc":"De menor a mayor","listing-page-field-date":"Fecha","listing-page-field-title":"Título","listing-page-field-description":"Descripción","listing-page-field-author":"Autor/a","listing-page-field-filename":"Nombre de archivo","listing-page-field-filemodified":"Fecha de modificación","listing-page-field-subtitle":"Subtítulo","listing-page-field-readingtime":"Tiempo de lectura","listing-page-field-wordcount":"Conteo de Palabras","listing-page-field-categories":"Categorías","listing-page-minutes-compact":"{0} minutos","listing-page-category-all":"Todas","listing-page-no-matches":"No hay resultados","listing-page-words":"{0} palabras","listing-page-filter":"Filtro","draft":"Borrador"},"metadata":{"block-headings":true,"bibliography":["references.bib"],"lang":"es","documentclass":"scrreprt","papersize":"us-letter","titlegraphic":"FCFMLOGO.png","institution":"Universidad Autónoma de Chiapas","email":"francisco.escobar30@unach.mx","link-citations":true,"title":"Predicciones del modelo"},"extensions":{"book":{"selfContainedOutput":true}}}},"projectFormats":["html","pdf"]}