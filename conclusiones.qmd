---
title: Conclusiones
lang: es
execute: 
  freeze: auto
---

::: {style="text-align: justify"}
El presente trabajo ha abordado la complejidad de resolver una ecuación diferencial parcial dependiente del tiempo en dos dimensiones espaciales a través de una red neuronal con la arquitectura DeepONet, asimismo se obtuvieron predicciones para el cuadrado de $[0,1]\times[0,1]$. Los hiperparámetros de la red se fueron variando para obtener la mejor configuración, usando como base los resultados obtenidos por @medical_rep. Los resultados obtenidos mediante la comparación con el método de Crank Nickolson demostraron que la red neuronal DeepONet se aproxima con un mínimo del 1.1% y un máximo del 6.7% para el error medio absoluto, y cometiendo un error mínimo del 6.4% y máximo del 20% para el error máximo absoluto [@tbl-errores].

Los errores obtenidos demuestran la eficacia del modelo para converger a la condición inicial, pues tal como se aprecia en la @fig-abs-errors, a medida que la ecuación evoluciona en el tiempo, las predicciones entre el método numérico y la red neuronal divergen. Aunque esto es probable que se deba a la naturaleza del método de Crank Nickolson, pues un pequeño error al inicio ocasionaría que conforme evoluciona la función, ésta cada vez se aleje más del valor real. Desafortunadamente no se cuenta con una base de datos que sirva como conjunto de validación por lo que no se puede asegurar que los resultados del método numérico sean los más óptimos para tomar como referencia.

Lo anterior evidencia el potencial que tiene las PINNs como herramienta auxiliar en la solución de ecuaciones diferenciales parciales, pues solo a través de la definición de la geometria y el espacio temporal (si es necesario) junto con algunos puntos en el dominio y las condiciones iniciales y/o de frontera probarón predecir de forma muy acertada el conjunto de prueba. Ésto representa una gran ventaja respecto a los modelos de Deep learning que necesitan una gran cantidad de datos para poder ser entrenados. Otro punto clave de las PINNs es su adaptabilidad al ruido [@karniadakis2021] donde se ha demostrado que incluso a pesar de que los problemas no están perfectamente bien planteados o si existen parámetros desconocidos la red puede producir resultados significativos. Siendo ambas situaciones mencionadas comúnes en el ámbito científico.

Complementado a las PINNs, la arquitectura DeepONet aprende operadores (mapeos entre espacios de funciones) en lugar de solo aproximar funciones a diferencia de las PINNs tradicionales, que predicen soluciones específicas para condiciones fijas, DeepONet es capaz de generalizar a nuevas condiciones iniciales/frontera sin reentrenamiento, gracias a su estructura de red dual (branch-trunk). Esto lo hace ideal para aplicaciones en tiempo real , como la *hipertermia*, donde las características del problema son suceptibles a cambios, como lo son las propiedades del cuerpo humano que varían en cada paciente. Un problema clave que se encontró es que al tener una estructura más compleja, los tiempos de entrenamiento respectos a las PINNs son mayores, sin embargo esto se ve bien compensado por su alta capacidad de adaptabilidad a nuevas condiciones ya sean iniciales o de frontera.

La creación de éste tipo de modelos, tanto PINNs clásicas como DeepONets se puede ver obstaculizada por el conocimiento en programación del investigador o estudiante que se plantee programarlos. Si bien tanto el ámbito científico como en la programación el pensamiento crítico, seguimiento lógico y abstracción de los problemas son pilares fundamentales; también es necesario familiarizarse con las librerías que implementan éste tipo de modelos, además es bastante recomendado tener una noción básica de como funciona una red neuronal y las partes que la componen. Lo anterior implica una inversión de tiempo y esfuerzo por parte de los interesados, cosa que cuando se lleva a cabo un experiemento o investigación no siempre es posible. Si bien éstas herramientas son bastante fascinantes y con mucho potencial, como cualquier nueva habilidad hay que practicar su uso para obtener resultados que valgan la pena.

Cabe mencionar que las apicaciones de las PINNs son tan amplias como lo es en sí en campo de las PDEs, si nos centramos únicamente en la medicina, está la *hipertermia* como tratamiento oncológico, la cual busca elevar la temperatura en tejidos tumorales (39-45°C) para potenciar terapias como radioterapia. Sin embargo, controlar la distribución térmica en tiempo real es un desafío. Las redes neuronales, especialmente DeepONet, permiten predecir la temperatura de forma rápida y precisa bajo distintas condiciones, optimizando la dosificación de calor y minimizando daños a tejidos sanos. Esto facilita terapias personalizadas y no invasivas, mejorando la eficacia clínica.






:::