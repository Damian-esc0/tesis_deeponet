---
title: Conclusiones
lang: es
execute: 
  freeze: auto
---

::: {style="text-align: justify"}
El presente trabajo ha abordado la complejidad de resolver una ecuación diferencial parcial dependiente del tiempo en dos dimensiones espaciales a través de una red neuronal con la arquitectura DeepONet, asimismo se obtuvieron predicciones para el cuadrado de $[0,1]\times[0,1]$. Los hiperparámetros de la red se fueron variando para obtener la mejor configuración, usando como base los resultados obtenidos por @medical_rep. Los resultados obtenidos mediante la comparación con el método de Crank Nickolson demostraron que la red neuronal DeepONet se aproxima con un mínimo del 1.1% y un máximo del 6.7% para el error medio absoluto, y cometiendo un error mínimo del 6.4% y máximo del 20% para el error máximo absoluto.

Los errores obtenidos demuestran la eficacia del modelo para converger a la condición inicial, pues tal como se aprecia en la @fig-abs-errors, a medida que la ecuación evoluciona en el tiempo, las predicciones entre el método numérico y la red neuronal divergen. Aunque esto es probable que se deba a la naturaleza del método de Crank Nickolson, pues un pequeño error al inicio ocasionaría que conforme evoluciona la función, ésta cada vez se aleje más del valor real. Desafortunadamente no se cuenta con una base de datos que sirva como conjunto de validación por lo que no se puede asegurar que los resultados del método numérico sean los más óptimos para tomar como referencia.

Lo anterior evidencia el potencial que tiene las PINNs como herramienta auxiliar en la solución de ecuaciones diferenciales parciales, pues solo a través de la definición de la geometria y el espacio temporal (si es necesario) junto con algunos puntos en el dominio y las condiciones iniciales y/o de frontera probarón predecir de forma muy acertada el conjunto de prueba. Ésto representa una gran ventaja respecto a los modelos de Deep learning que necesitan una gran cantidad de datos para poder ser entrenados, cosa que en el ámbito científico no siempre es posible.

Complementado a las PINNs, la arquitectura DeepONet aprende operadores (mapeos entre espacios de funciones) en lugar de solo aproximar funciones a diferencia de las PINNs tradicionales, que predicen soluciones específicas para condiciones fijas, DeepONet es capaz de generalizar a nuevas condiciones iniciales/frontera sin reentrenamiento, gracias a su estructura de red dual (branch-trunk). Esto lo hace ideal para aplicaciones en tiempo real, como hipertermia, donde se requiere adaptabilidad a parámetros variables y eficiencia computacional. Su capacidad para aprender operadores no lineales amplía su utilidad en problemas multifísica y multiescala.

Finalmente, las apicaciones de las PINNs son tan amplias como lo es en sí en campo de las PDEs, centrándonos en la medicina está la hipertermia como tratamiento oncológico, la cual busca elevar la temperatura en tejidos tumorales (39-45°C) para potenciar terapias como radioterapia. Sin embargo, controlar la distribución térmica en tiempo real es un desafío. Las redes neuronales, especialmente DeepONet, permiten predecir la temperatura de forma rápida y precisa bajo distintas condiciones, optimizando la dosificación de calor y minimizando daños a tejidos sanos. Esto facilita terapias personalizadas y no invasivas, mejorando la eficacia clínica.






:::