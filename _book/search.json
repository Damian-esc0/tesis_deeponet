[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Estimación de la temperatura con la ecuacion del Bio-Calor usando DeepONet",
    "section": "",
    "text": "Resumen\nAquí irá el resumen de la tesis.",
    "crumbs": [
      "Resumen"
    ]
  },
  {
    "objectID": "metodo-num.html",
    "href": "metodo-num.html",
    "title": "2  Aplicacion de Crank Nikolson",
    "section": "",
    "text": "Código\nusing DifferentialEquations, LinearAlgebra\nusing DataFrames, CSV\n\n# --- PARÁMETROS FÍSICOS Y DIMENSIONALES ------------------------------------\nρ, c  = 1050.0, 3639.0                        # densidad, calor específico \nk_eff = 5.0                                   # conductividad\nt_f   = 1800.0                                # tiempo final \nL     = 0.05                                  # longitud del dominio\nc_b   = 3825.0                                # coef. perfusión\nQ     = 0.0                                   # fuente térmica\nT_M, T_a = 45.0, 37.0                         # temp máxima, temp ambiente\n\n# --- COEFICIENTES ADIMENSIONALES -------------------------------------------\nα = ρ * c / k_eff\na₁ = t_f / (α * L^2)\na₂ = t_f * c_b / (ρ * c)\na₃ = (t_f * Q) / (ρ * c * (T_M - T_a))\n\n# --- MALLA ESPACIAL ---------------------------------------------------------\nNx, Ny = 51, 51\ndx, dy = 1.0 / (Nx - 1), 1.0 / (Ny - 1)\nx = range(0, 1, length=Nx)\ny = range(0, 1, length=Ny)\nN = Nx * Ny  # total de puntos\n\n# --- CONDICIÓN INICIAL ------------------------------------------------------\nu0 = zeros(N)\n\n# --- SISTEMA DE EDOs DEL PDE ------------------------------------------------\nfunction f!(du, u, _, τ)\n    U = reshape(u, Nx, Ny)\n    D = similar(U)\n    @inbounds for i in 1:Nx, j in 1:Ny\n        # Derivadas segunda en x\n        d2x = if i == 1\n            (U[2, j] - 0) / dx^2\n        elseif i == Nx\n            U_ghost = U[Nx, j] + τ * dx\n            (U_ghost - 2U[Nx, j] + U[Nx-1, j]) / dx^2\n        else\n            (U[i+1, j] - 2U[i, j] + U[i-1, j]) / dx^2\n        end\n\n        # Derivadas segunda en y\n        d2y = if j == 1\n            (U[i, 2] - U[i, 1]) / dy^2\n        elseif j == Ny\n            (U[i, Ny-1] - U[i, Ny]) / dy^2\n        else\n            (U[i, j+1] - 2U[i, j] + U[i, j-1]) / dy^2\n        end\n\n        D[i, j] = (d2x + d2y - a₂ * U[i, j] + a₃) / a₁\n    end\n    du .= vec(D)\nend\n\n# --- RESOLVER PDE ---------------------------------------------------------\nτspan = (0.0, 1.0)\nprob = ODEProblem(f!, u0, τspan)\ntaus = [0.0, 0.25, 0.5, 0.75, 1.0]\nsol = solve(prob, Trapezoid(), dt=8e-4, saveat=taus)\n\n# --- PROCESAR SOLUCIÓN EN GRILLA REDUCIDA ---------------------------------\nidxs = 1:2:Nx  # índices para submuestreo\nnpts = length(idxs)^2 * length(taus)\n\n# Preasignar vectores para crear el DataFrame\ntimes = Float64[]\nXs = Float64[]\nYs = Float64[]\nThetas = Float64[]\n\nfor (k, τ) in enumerate(taus)\n    Θ = reshape(sol(τ), Nx, Ny)\n    for j in idxs, i in idxs\n        push!(times, τ)\n        push!(Xs, x[i])\n        push!(Ys, y[j])\n        push!(Thetas, Θ[i, j])\n    end\nend\n\ndf = DataFrame(time=times, X=Xs, Y=Ys, Theta=Thetas)\n\n# --- GUARDAR CSV ------------------------------------------------------------\nruta = \"data\"\nCSV.write(joinpath(ruta, \"crank_nick.csv\"), df)\n\n\n\n\nCódigo\nusing DataFrames, CSV, Plots, Statistics\npyplot()\n\n# --- OBTENER VALORES ÚNICOS Y ORDENADOS DE X, Y, TIME ----------------------\nx_vals = sort(unique(df.X))\ny_vals = sort(unique(df.Y))\ntimes = sort(unique(df.time))  # tiempos\n\nNx, Ny = length(x_vals), length(y_vals)\n\n# --- RECONSTRUIR MATRICES 2D DE THETA PARA CADA TIEMPO ---------------------\nsolutions = []\n\nfor t in times\n    dft = filter(:time =&gt; ==(t), df)\n\n    # Crear matriz vacía\n    Θ = fill(NaN, Nx, Ny)\n\n    # Llenar la matriz con los valores correspondientes\n    for row in eachrow(dft)\n        ix = findfirst(==(row.X), x_vals)\n        iy = findfirst(==(row.Y), y_vals)\n        Θ[ix, iy] = row.Theta\n    end\n\n    push!(solutions, Θ)\nend\n\n# --- DETERMINAR ESCALA GLOBAL DE COLORES -----------------------------------\nzmin = minimum([minimum(u) for u in solutions])\nzmax = maximum([maximum(u) for u in solutions])\n\n# --- GRAFICAR EN LAYOUT 3x2 ------------------------------------------------\np = plot(layout = (3, 2), size = (800, 900))\n\nfor (i, (t, Θ)) in enumerate(zip(times, solutions))\n    surface!(\n        p, y_vals, x_vals, Θ;  # transpuesta para que coincidan con x, y\n        camera = (45,30),\n        xlabel = \"Y\",\n        ylabel = \"X\",\n        zlabel = \"T   \",\n        title = \"t = $(t)\",\n        subplot = i,\n        c = :thermal,\n        clim = (zmin, zmax),\n        legend = false\n    )\nend\n\n# Eliminar ejes y contenido del subplot 6\nplot!(p[6], framestyle = :none, grid = false, xticks = false, yticks = false)\nclose(\"all\")\n\ndisplay(p)\n\n\n\n\n\n\n\n \n  \n   \n    \n    2025-06-01T23:10:26.815620\n    image/svg+xml\n    \n     \n      Matplotlib v3.7.5, https://matplotlib.org/",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Aplicacion de Crank Nikolson</span>"
    ]
  },
  {
    "objectID": "pinns.html#comparación-con-redes-neuronales-tradicionales",
    "href": "pinns.html#comparación-con-redes-neuronales-tradicionales",
    "title": "6  Physic Informed Neural Networks (PINNs)",
    "section": "6.1 Comparación con Redes Neuronales Tradicionales",
    "text": "6.1 Comparación con Redes Neuronales Tradicionales\nMientras que las redes neuronales tradicionales dependen exclusivamente de grandes volúmenes de datos etiquetados para su entrenamiento (Karniadakis et al. 2021), las PINNs integran el conocimiento físico como parte esencial de su arquitectura (Blechschmidt y Ernst 2021). Esta diferencia clave permite a las PINNs generar soluciones físicamente consistentes incluso con datos escasos, evitando el sobreajuste común en enfoques puramente basados en datos. Otra ventaja significativa de las PINNs es su naturaleza mesh-free, que contrasta con los métodos numéricos tradicionales como FEM o FDM que requieren discretización espacial. Sin embargo, el entrenamiento de PINNs puede ser más desafiante debido a la necesidad de optimizar múltiples objetivos simultáneamente (ajuste a datos y cumplimiento de leyes físicas) (Blechschmidt y Ernst 2021; Karniadakis et al. 2021).",
    "crumbs": [
      "Redes neuronales",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Physic Informed Neural Networks (PINNs)</span>"
    ]
  },
  {
    "objectID": "deeponet.html#arquitectura",
    "href": "deeponet.html#arquitectura",
    "title": "4  DeepONet",
    "section": "4.1 Arquitectura",
    "text": "4.1 Arquitectura\nLa arquitectura de DeepONet está compuesta por dos redes principales: la red de branch y la red de trunk. La red branch procesa las evaluaciones discretas de la función de entrada (por ejemplo, condiciones iniciales o de frontera), mientras que la red trunk recibe como entrada los puntos del dominio donde se desea evaluar la función de salida. La salida final se obtiene mediante el producto punto de los vectores generados por ambas redes, lo que permite representar operadores complejos con alta generalización a nuevos datos (Lu et al. 2021).\n\n\n\n\n\n\nFigura 4.1: Ilustraciones del planteamiento del problema y arquitectura DeepONet que conducen a una buena generalización. a) Para que la red aprenda un operador \\(G : u \\rightarrow G(u)\\) se necesitan dos entradas \\([u(x_1), u(x_2), ..., u(x_m)]\\) e \\(y\\). b) Ilustración de los datos de entrenamiento. Para cada función de entrada \\(u\\), se requiere el mismo número de evaluaciones en los mismos sensores dispersos \\(x_1, x_2, ..., x_m\\). Sin embargo, no se impone ninguna restricción sobre el número ni las ubicaciones para la evaluación de las funciones de salida. c) La DeepONet stacked se inspira en el Teorema de aproximación universal para operadores y consta de una red Trunk y \\(p\\) redes Branch apiladas. La red cuya construcción se inspira en el mismo teorema es una DeepONet stacked formada al elegir la red Trunk como una red de una capa de ancho \\(p\\) y cada red Branch como una red de una capa oculta de ancho \\(n\\). d) La red DeepONet unstacked se inspira en el Teorema general de aproximación universal para operadores y consta de una red Trunk y una red Branch. Una red DeepONet unstacked puede considerarse como una red DeepONet stacked, en la que todas las redes Branch comparten el mismo conjunto de parámetros (Lu et al. 2021).",
    "crumbs": [
      "Redes neuronales",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>DeepONet</span>"
    ]
  },
  {
    "objectID": "deeponet.html#comparación-con-una-pinn",
    "href": "deeponet.html#comparación-con-una-pinn",
    "title": "4  DeepONet",
    "section": "4.2 Comparación con una PINN",
    "text": "4.2 Comparación con una PINN\nEn contraste con una red PINN convencional (Physics-Informed Neural Network), que resuelve una instancia específica de una ecuación diferencial para un conjunto dado de condiciones, DeepONet aprende el operador general que resuelve muchas instancias a la vez. Mientras que una PINN debe ser reentrenada para cada nuevo problema, DeepONet, una vez entrenado, puede predecir soluciones rápidamente para múltiples condiciones nuevas. Esto lo hace especialmente eficiente en aplicaciones donde se requiere realizar inferencias repetidas, como en control o diseño inverso (Kumar et al. 2024).",
    "crumbs": [
      "Redes neuronales",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>DeepONet</span>"
    ]
  },
  {
    "objectID": "PBHE.html#experimento",
    "href": "PBHE.html#experimento",
    "title": "Ecuación del Bio-Calor",
    "section": "Experimento",
    "text": "Experimento\nDurante su estudio, Pennes diseñó un experimento riguroso para medir la temperatura interna del antebrazo humano. Utilizó termopares tipo “Y” insertados transversalmente en la musculatura del antebrazo mediante una aguja estéril, como se ilustra en la Figura 1. Esta configuración permitía capturar un perfil térmico a lo largo del eje transversal, minimizando interferencias derivadas del contacto externo o la conducción axial no deseada.\nLa técnica experimental buscó máxima precisión geométrica y térmica: los termopares eran fijados con tensión controlada mediante un sistema mecánico que aseguraba trayectorias rectas y repetibles dentro del tejido. La inserción se realizaba con anestesia tópica mínima y bajo condiciones ambientales estables, lo cual garantizaba que los gradientes de temperatura registrados fueran atribuibles principalmente al metabolismo local y al efecto del flujo sanguíneo arterial.\n\n\n\n\n\n\nFigura 1: a) Posición del brazo derecho (vista superior). La linea horizontal II indica el nivel de la figura c). b) Posición del brazo derecho (vista lateral). c)Sección transversal anatómica del antebrazo en el nivel II (Pennes 1948).",
    "crumbs": [
      "Ecuación del Bio-Calor"
    ]
  },
  {
    "objectID": "PBHE.html#trascendencia",
    "href": "PBHE.html#trascendencia",
    "title": "Ecuación del Bio-Calor",
    "section": "Trascendencia",
    "text": "Trascendencia\nEl modelo de Pennes simplificó la complejidad biológica al asumir un flujo sanguíneo uniforme y una transferencia de calor proporcional a la diferencia entre la temperatura arterial y la tisular. Aunque posteriores investigaciones refinaron sus supuestos, su ecuación sigue siendo un referente en bioingeniería térmica. Su trabajo no solo sentó las bases para aplicaciones clínicas, como la hipertermia oncológica, sino que también inspiró avances en el estudio de la termorregulación humana y el diseño de dispositivos médicos.",
    "crumbs": [
      "Ecuación del Bio-Calor"
    ]
  },
  {
    "objectID": "ecuacion.html#versión-reducida-adimensionalizada",
    "href": "ecuacion.html#versión-reducida-adimensionalizada",
    "title": "5  Forma de la ecuación",
    "section": "5.1 Versión reducida (adimensionalizada)",
    "text": "5.1 Versión reducida (adimensionalizada)\nMediante escalamiento: \\[\\begin{equation*}\nT' = T - T_a \\qquad \\theta = \\dfrac{T'}{T_M - T_a} \\qquad X = \\dfrac{x}{L_0} \\qquad \\tau = \\dfrac{t}{t_f}\n\\end{equation*}\\]\n\n\n\nTabla 5.2: Tabla de nomenclatura de las relaciones para escalamiento.\n\n\n\n\n\nSímbolo\nDescripción\nUnidades\n\n\n\n\n\\(L_0\\)\nLongitud característica del dominio\n\\(m\\)\n\n\n\\(t_f\\)\nTiempo final de simulación\n\\(s\\)\n\n\n\n\n\n\nla Ecuación 5.1 se convierte en:\n\\[\n\\partial_{\\tau} \\theta = a_1 \\partial_{XX} \\theta - a_2 W \\theta + a_3\n\\tag{5.2}\\]\nParámetros adimensionales:\n- \\(a_1 = \\frac{t_f}{\\alpha L_0^2}\\) (difusividad térmica \\(\\alpha = \\frac{k_{\\text{eff}}}{\\rho c}\\)).\n- \\(a_2 = \\frac{t_f c_b}{\\rho c}\\).\n- \\(a_3 = \\frac{t_f Q}{\\rho c (T_M - T_a)}\\).\n- \\(W = \\rho_b \\omega_b\\): Tasa volumétrica de perfusión (kg/m³·s).",
    "crumbs": [
      "Ecuación del Bio-Calor",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Forma de la ecuación</span>"
    ]
  },
  {
    "objectID": "ecuacion.html#condiciones-de-uso-adecuadas",
    "href": "ecuacion.html#condiciones-de-uso-adecuadas",
    "title": "5  Forma de la ecuación",
    "section": "5.2 Condiciones de uso adecuadas",
    "text": "5.2 Condiciones de uso adecuadas\n\nTejidos homogéneos: Aproximación válida para regiones con propiedades térmicas uniformes.\n\nPerfusión sanguínea constante: Supone flujo sanguíneo estable en el dominio.\n\nAplicaciones clínicas: Hipertermia, crioterapia y modelado térmico en terapias oncológicas.",
    "crumbs": [
      "Ecuación del Bio-Calor",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Forma de la ecuación</span>"
    ]
  },
  {
    "objectID": "ejemplos.html#aplicaciones-recientes-de-la-ecuación-del-bio-calor",
    "href": "ejemplos.html#aplicaciones-recientes-de-la-ecuación-del-bio-calor",
    "title": "6  Modelado del Bio-Calor en Hipertermia",
    "section": "6.1 Aplicaciones recientes de la ecuación del bio-calor",
    "text": "6.1 Aplicaciones recientes de la ecuación del bio-calor\nQuintero et al. (2017) desarrollan un modelo basado en ecuaciones diferenciales parciales que integra la ecuación del bio-calor y la ley de Arrhenius para estimar el daño térmico en tratamientos de hipertermia superficial. Utilizan el método de líneas para resolver el sistema y plantean un problema de optimización que busca maximizar el daño al tejido tumoral minimizando el daño colateral. Su trabajo demuestra cómo la modelación matemática puede guiar estrategias terapéuticas más seguras y eficaces.\nDutta y Rangarajan (2018) presentan una solución analítica cerrada en dos dimensiones para la ecuación del bio-calor, considerando modelos de conducción tanto de tipo Fourier como no-Fourier. Mediante el uso de la transformada de Laplace, analizan la influencia de parámetros fisiológicos como la perfusión sanguínea y el tiempo de relajación térmica sobre la evolución de la temperatura. Su investigación aporta una base teórica sólida para comprender la propagación térmica en tejidos vivos durante la hipertermia terapéutica.\nYang et al. (2014) propone una estrategia numérica para resolver problemas inversos de conducción térmica en tejidos biológicos multicapa, utilizando un enfoque en diferencias finitas y el concepto de tiempo futuro. El estudio se enfoca en predecir las condiciones de frontera necesarias para generar distribuciones de temperatura deseadas. La implementación de este método permite estimar parámetros relevantes en tiempo real, lo cual resulta esencial para el control térmico preciso en procedimientos médicos no invasivos como la hipertermia localizada.",
    "crumbs": [
      "Ecuación del Bio-Calor",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Modelado del Bio-Calor en Hipertermia</span>"
    ]
  },
  {
    "objectID": "estudio_caso.html",
    "href": "estudio_caso.html",
    "title": "Estudio de caso",
    "section": "",
    "text": "Hipertermia como opción terapéutica complementaria en el manejo de cáncer",
    "crumbs": [
      "Estudio de caso"
    ]
  },
  {
    "objectID": "estudio_caso.html#hipertermia-como-opción-terapéutica-complementaria-en-el-manejo-de-cáncer",
    "href": "estudio_caso.html#hipertermia-como-opción-terapéutica-complementaria-en-el-manejo-de-cáncer",
    "title": "Estudio de caso",
    "section": "",
    "text": "La Organización Mundial de la Salud (2022) en su página web define Cáncer como:\n\n«Cáncer» es un término genérico utilizado para designar un amplio grupo de enfermedades que pueden afectar a cualquier parte del organismo; también se habla de «tumores malignos» o «neoplasias malignas». Una característica definitoria del cáncer es la multiplicación rápida de células anormales que se extienden más allá de sus límites habituales y pueden invadir partes adyacentes del cuerpo o propagarse a otros órganos, en un proceso que se denomina «metástasis». La extensión de las metástasis es la principal causa de muerte por la enfermedad.\n\nPor su parte Instituto Nacional del Cáncer (2021) aporta lo siguiente:\n\nEs posible que el cáncer comience en cualquier parte del cuerpo humano, formado por billones de células. En condiciones normales, las células humanas se forman y se multiplican (mediante un proceso que se llama división celular) para formar células nuevas a medida que el cuerpo las necesita. Cuando las células envejecen o se dañan, mueren y las células nuevas las reemplazan. A veces el proceso no sigue este orden y las células anormales o células dañadas se forman y se multiplican cuando no deberían. Estas células tal vez formen tumores, que son bultos de tejido. Los tumores son cancerosos (malignos) o no cancerosos (benignos).\n\n\n\n\n\n\n\nFigura 1: Una célula de cáncer de seno que se multiplica (Instituto Nacional del Cáncer 2021).\n\n\n\nÉsta enfermedad es la principal causa de muerte a nivel mundial, solo en 2020 arrebató casi 10 millones de vidas y según datos de Organización Mundial de la Salud (2022) los cánceres más comunes en 2020 fueron:\n\nDe mama (2.26 millones de casos)\nDe pulmón (2.21 millones de casos)\nDe colon (1.93 millones de casos)\nDe próstata (1.41 millones de casos)\nDe piel (distinto del melanoma) (1.20 millones de casos)\nGástrico (1.09 millones de casos)\n\nEs ante este panorama que distintos tratamientos surgen con el objetivo de erradicar la enfermedad siempre que se tenga una detección oportuna. Uno de dichos tratamientos es la hipertermia, según en el National Cancer Institute (2021) es un método que consiste en calentar el tejido corporal hasta los 39-45 °C para ayudar a erradicar células cancerígenas con pequeñas o nulas lesiones en el tejido sano. La hipertermia también es llamada terapia térmica o termoterapia.\nUno de los principales retos de este tratamiento es la creación de un modelo óptimo que se adecue al comportamiento de la transferencia de calor que se hace a los tejidos con el fin de dañar únicamente el área en el que se encuentran las célular cancerígenas, es por ello que los modelos de integencia artificial y más precisamente las PINN’s (aqui irá una cita) surgen como posible solución a este reto.\nEl presente estudio utilizó como punto de partida el trabajo realizado por Alessio Borgi (2023) para modelar el calentamiento del tejido corporal usando la ecuación del Bio-Calor en dos dimensiones.\n\n\n\n\n\nAlessio Borgi, Alessandro De Luca, Eugenio Bugli. 2023. «BioHeat PINNs: Temperature Estimation with Bio-Heat Equation using Physics-Informed Neural Networks». https://github.com/alessioborgi/BioHeat_PINNs/tree/main?tab=readme-ov-file#bioheat-pinns-temperature-estimation-with-bio-heat-equation-using-physics-informed-neural-networks.\n\n\nInstituto Nacional del Cáncer. 2021. «¿Qué es el cáncer?» https://www.cancer.gov/espanol/cancer/naturaleza/que-es.\n\n\nNational Cancer Institute. 2021. «Hyperthermia to Treat Cancer». https://www.cancer.gov/about-cancer/treatment/types/hyperthermia.\n\n\nOrganización Mundial de la Salud. 2022. «Cáncer». https://www.who.int/es/news-room/fact-sheets/detail/cancer.",
    "crumbs": [
      "Estudio de caso"
    ]
  },
  {
    "objectID": "metodologia.html#aportaciones-del-modelo",
    "href": "metodologia.html#aportaciones-del-modelo",
    "title": "7  Metodología",
    "section": "7.1 Aportaciones del modelo",
    "text": "7.1 Aportaciones del modelo\nYa que se parte del trabajo de Alessio Borgi (2023), se examinó que dos de los puntos a mejorar de la red neuronal que plantearon son:\n\nDesarrollar nuevas arquitecturas para la red neuronal y explorar nuevas configuraciones\nCombinar las fortalezas de los algoritmos de optimización Adam y L-BFGS para mejorar la velocidad de convergencia y la precisión\n\nTenindo los anteriores puntos en cuenta, se procedió a abordarlos e implementarlos dentro del diseño del modelo.",
    "crumbs": [
      "Estudio de caso",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Metodología</span>"
    ]
  },
  {
    "objectID": "metodologia.html#diseño-del-modelo",
    "href": "metodologia.html#diseño-del-modelo",
    "title": "7  Metodología",
    "section": "7.2 Diseño del modelo",
    "text": "7.2 Diseño del modelo\nEl lenguaje seleccionado fué Python, a su vez el código se basa enteramente en la librería Deepxde creada por Lu et al. (2021) la cual está directamente enfocada a resolver ecuaciones diferenciales, se usó además como backend tensorflow_compat_v1 siendo su elección debida únicamente a la familiarización previa que se tenía con ella. Finalmente el entorno donde se programó y optimizó el código fué en Google Colab ya que la potencia de cómputo ofrecida por la plataforma era necesaria para ejecutar el modelo.",
    "crumbs": [
      "Estudio de caso",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Metodología</span>"
    ]
  },
  {
    "objectID": "metodologia.html#implementación-del-modelo",
    "href": "metodologia.html#implementación-del-modelo",
    "title": "7  Metodología",
    "section": "7.3 Implementación del modelo",
    "text": "7.3 Implementación del modelo\nUna vez creado el código que resuelve la ecuación del Bio-Calor, se ajustaron los hiperparámetros tales como cantidad de épocas de entrenamiento, el ratio de aprendizaje, la función de activación y el inicializador en base al trabajo de Alessio Borgi (2023).",
    "crumbs": [
      "Estudio de caso",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Metodología</span>"
    ]
  },
  {
    "objectID": "metodologia.html#evaluación-del-modelo",
    "href": "metodologia.html#evaluación-del-modelo",
    "title": "7  Metodología",
    "section": "7.4 Evaluación del modelo",
    "text": "7.4 Evaluación del modelo\nSe llevó a cabo una evaluación del modelo al darle como entrada un conjunto de datos que no había visto y posteriormente obtener como salida sus predicciones, con ellas se elaboraron gráficas claras y detalladas de su pronóstico en el intervalo de tiempo y espacio especificados.",
    "crumbs": [
      "Estudio de caso",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Metodología</span>"
    ]
  },
  {
    "objectID": "metodologia.html#comparación-de-resultados",
    "href": "metodologia.html#comparación-de-resultados",
    "title": "7  Metodología",
    "section": "7.5 Comparación de resultados",
    "text": "7.5 Comparación de resultados\nLos resultados obtenidos de la evaluación del modelo fueron comparados con los del trabajo de Alessio Borgi (2023) para determinar su eficacia predictiva relativa. Se analizaron las fortalezas y debilidades del modelo en función de su desempeño en la predicción de las variables de interés.",
    "crumbs": [
      "Estudio de caso",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Metodología</span>"
    ]
  },
  {
    "objectID": "metodologia.html#análisis-y-conclusión",
    "href": "metodologia.html#análisis-y-conclusión",
    "title": "7  Metodología",
    "section": "7.6 Análisis y conclusión",
    "text": "7.6 Análisis y conclusión\nFinalmente, se realizó un análisis detallado de los resultados obtenidos para extraer conclusiones significativas. Se proporcionaron recomendaciones basadas en los hallazgos del estudio, lo que permitió establecer un marco para interpretaciones analíticas profundas y recomendaciones bien fundamentadas en la sección de conclusiones del estudio.\nEste enfoque metodológico proporcionó una base sólida para los resultados obtenidos, asegurando la integridad y la calidad del análisis realizado en el estudio.",
    "crumbs": [
      "Estudio de caso",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Metodología</span>"
    ]
  },
  {
    "objectID": "predicciones.html",
    "href": "predicciones.html",
    "title": "11  Predicciones del modelo",
    "section": "",
    "text": "11.1 Comparación con el método de Crank Nickolson\nPara tener un valor numérico con el cual conocer al veracidad del modelo se comparó con las predicciones del método de Crank Nickolson\nCódigo\nimport os\n\n# Definir los tiempos a evaluar\ntimes = [0.0, 0.25, 0.5, 0.75, 1.0]\n\n# Rutas de los archivos (modificar según sea necesario)\ncrank_nick_path = \"data/crank_nick.csv\"\nmodel_don_path = \"data/model_DoN.csv\"\noutput_path = \"data/error_comparison.csv\"\n\n# Cargar los datos\ndef load_data(file_path):\n    try:\n        return pd.read_csv(file_path)\n    except FileNotFoundError:\n        print(f\"Error: No se encontró el archivo {file_path}\")\n        return None\n    except Exception as e:\n        print(f\"Error al cargar {file_path}: {str(e)}\")\n        return None\n\ncrank_nick_data = load_data(crank_nick_path)\nmodel_don_data = load_data(model_don_path)\n\nif crank_nick_data is None or model_don_data is None:\n    exit()\n\n# Función para calcular errores\ndef calculate_errors(true_data, pred_data, times):\n    results = []\n    \n    for time in times:\n        # Filtrar datos por tiempo\n        true_subset = true_data[true_data['time'] == time]\n        pred_subset = pred_data[pred_data['time'] == time]\n        \n        if len(true_subset) == 0 or len(pred_subset) == 0:\n            print(f\"Advertencia: No hay datos para tiempo t={time}\")\n            continue\n        \n        # Verificar que las dimensiones coincidan\n        if len(true_subset) != len(pred_subset):\n            print(f\"Advertencia: Número de puntos no coincide para t={time}\")\n            min_len = min(len(true_subset), len(pred_subset))\n            true_subset = true_subset.iloc[:min_len]\n            pred_subset = pred_subset.iloc[:min_len]\n        \n        # Calcular errores para Theta\n        theta_true = true_subset['Theta'].values\n        theta_pred = pred_subset['Theta'].values\n        \n        absolute_error = np.abs(theta_true - theta_pred)\n        l2_error = np.sqrt(np.sum((theta_true - theta_pred)**2))\n        \n        results.append({\n            'time': time,\n            'mean_absolute_error': np.mean(absolute_error),\n            'max_absolute_error': np.max(absolute_error),\n            'l2_error': l2_error\n        })\n    \n    return pd.DataFrame(results)\n\n# Calcular errores\nerror_results = calculate_errors(crank_nick_data, model_don_data, times)\n\n# Guardar resultados\nerror_results.to_csv(output_path, index=False)\nTabla 11.2: Errores de la red neuronal.\n\n\n\n|   time |   mean_absolute_error |   max_absolute_error |   l2_error |\n|-------:|----------------------:|---------------------:|-----------:|\n|   0    |             0.0148105 |            0.0410959 |   0.434828 |\n|   0.25 |             0.0287047 |            0.0814783 |   0.970444 |\n|   0.5  |             0.0111502 |            0.0181923 |   0.326239 |\n|   0.75 |             0.0392763 |            0.123815  |   1.3829   |\n|   1    |             0.100083  |            0.273261  |   3.33132  |",
    "crumbs": [
      "Estudio de caso",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Predicciones del modelo</span>"
    ]
  },
  {
    "objectID": "predicciones.html#comparación-con-el-método-de-crank-nickolson",
    "href": "predicciones.html#comparación-con-el-método-de-crank-nickolson",
    "title": "11  Predicciones del modelo",
    "section": "",
    "text": "Alessio Borgi, Alessandro De Luca, Eugenio Bugli. 2023. «BioHeat PINNs: Temperature Estimation with Bio-Heat Equation using Physics-Informed Neural Networks». https://github.com/alessioborgi/BioHeat_PINNs/tree/main?tab=readme-ov-file#bioheat-pinns-temperature-estimation-with-bio-heat-equation-using-physics-informed-neural-networks.",
    "crumbs": [
      "Estudio de caso",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Predicciones del modelo</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "Referencias",
    "section": "",
    "text": "Alessio Borgi, Alessandro De Luca, Eugenio Bugli. 2023. “BioHeat PINNs: Temperature Estimation with Bio-Heat\nEquation using Physics-Informed Neural Networks.” https://github.com/alessioborgi/BioHeat_PINNs/tree/main?tab=readme-ov-file#bioheat-pinns-temperature-estimation-with-bio-heat-equation-using-physics-informed-neural-networks.\n\n\nBlechschmidt, Jan, and Oliver G. Ernst. 2021. “Three Ways to Solve\nPartial Differential Equations with Neural Networks—a Review.”\nGAMM-Mitteilungen 44 (2): e202100006. https://doi.org/10.1002/gamm.202100006.\n\n\nBurden, Richard L., and J. Douglas Faires. 2010. “Numerical\nAnalysis.” In Numerical Analysis, 9th ed., 259–64.\nBoston, USA: Brooks Cole.\n\n\nDutta, Abhijit, and Gopal Rangarajan. 2018. “Diffusion in\nPharmaceutical Systems: Modelling and Applications.” Journal\nof Pharmacy and Pharmacology 70 (5): 581–98. https://doi.org/10.1111/jphp.12885.\n\n\nInstituto Nacional del Cáncer. 2021. “¿Qué es\nel cáncer?” https://www.cancer.gov/espanol/cancer/naturaleza/que-es.\n\n\nKarniadakis, George Em, Ioannis G. Kevrekidis, Lu Lu, Paris Perdikaris,\nSifan Wang, and Liu Yang. 2021. “Physics-Informed Machine\nLearning.” Nature Reviews Physics 3 (6): 422–40. https://doi.org/10.1038/s42254-021-00314-5.\n\n\nKumar, Varun, Somdatta Goswami, Katiana Kontolati, Michael D. Shields,\nand George Em Karniadakis. 2024. “Synergistic Learning with\nMulti-Task DeepONet for Efficient PDE Problem Solving.” arXiv\nPreprint arXiv:2408.02198. https://arxiv.org/abs/2408.02198.\n\n\nLu, Lu, Pengzhan Jin, Guofei Pang, Zhongqiang Zhang, and George Em\nKarniadakis. 2021. “Learning Nonlinear Operators via DeepONet\nBased on the Universal Approximation Theorem of Operators.”\nNature Machine Intelligence 3 (3): 218–29. https://doi.org/10.1038/s42256-021-00302-5.\n\n\nLu, Lu, Xuhui Meng, Zhiping Mao, and George Em Karniadakis. 2021.\n“DeepXDE: A Deep Learning Library for Solving\nDifferential Equations.” SIAM Review 63 (1): 208–28. https://doi.org/10.1137/19M1274067.\n\n\nNational Cancer Institute. 2021. “Hyperthermia to Treat Cancer.” https://www.cancer.gov/about-cancer/treatment/types/hyperthermia.\n\n\nOrganización Mundial de la Salud. 2022.\n“Cáncer.” https://www.who.int/es/news-room/fact-sheets/detail/cancer.\n\n\nPennes, H. H. 1948. “Analysis of Tissue and Arterial Blood\nTemperatures in the Resting Human Forearm.” Journal of\nApplied Physiology 1 (2): 93–122. https://doi.org/10.1152/jappl.1948.1.2.93.\n\n\nQuintero, Luis A., Mauricio Peñuela, Armando Zambrano, and Edwin\nRodríguez. 2017. “Optimización Del Proceso de Preparación de\nSoluciones Madre de Antibióticos En Un Servicio Farmacéutico\nHospitalario.” Revista Cubana de Farmacia 50 (2):\n448–65. https://www.medigraphic.com/cgi-bin/new/resumen.cgi?IDARTICULO=75483.\n\n\nYang, Lihong, Xin Wu, Qian Wan, Jian Kong, Rui Liu, and Xiaoxi Liu.\n2014. “Pharmaceutical Preparation of Antibiotics: A Review on\nFormulation and Technique.” Asian Journal of Pharmaceutical\nSciences 9 (3): 145–53. https://doi.org/10.1016/j.ajps.2014.04.001.",
    "crumbs": [
      "Referencias"
    ]
  },
  {
    "objectID": "initial_values.html",
    "href": "initial_values.html",
    "title": "4  Problemas de valores iniciales",
    "section": "",
    "text": "Las ecuaciones diferenciales se utilizan para modelar problemas en ciencia e ingeniería que implican el cambio de una variable con respecto a otra. La mayoría de estos problemas requieren la solución de un problema de valor inicial, es decir, la solución de una ecuación diferencial que satisface una condición inicial dada.\nEn situaciones reales comunes, la ecuación diferencial que modela el problema es demasiado compleja para resolverse con exactitud, y se adopta uno de dos enfoques para aproximar la solución. El primer enfoque consiste en modificar el problema simplificando la ecuación diferencial a una que pueda resolverse con exactitud y luego utilizar la solución de la ecuación simplificada para aproximar la solución del problema original. El otro enfoque utiliza métodos para aproximar la solución del problema original. Este es el enfoque más común porque los métodos de aproximación proporcionan resultados más precisos e información de error realista (Burden y Faires 2010).\n\n\n\n\n\n\nEjemplo\n\n\n\n\n\nEl movimiento de un péndulo oscilante bajo ciertas suposiciones se describe mediante la ecuación diferencial de segundo orden: \\[\n\\dfrac{d^2 \\theta}{d t^2} + \\dfrac{g}{L} \\sin{\\theta} = 0\n\\]\nDonde \\(L\\) es la longitud del péndulo, \\(g \\approx 9.81 \\frac{m}{s^2}\\) es la constante gravitacional terrestre y \\(\\theta\\) es el ángulo que forma el péndulo con la vertical. Si, además, especificamos la posición del péndulo al inicio del movimiento, \\(\\theta(t_0) = \\theta_{0}\\) , y su velocidad en ese punto, \\(\\theta'(t_0) = \\theta'_0\\). Tenemos un problema de valor inicial.\n\n\n\n\nDefinición 4.1 Se dice que una función \\(f(t,y)\\) satisface una Condición de Lipschitz en la variable \\(y\\) en un conjunto \\(D \\subset \\mathbb{R}^2\\) si existe una constante \\(L&gt;0\\) tal que \\[\n|f(t,y_1) - f(t,y_2)| \\leq L|y_1-y_2|\n\\]\ndonde \\(f(t,y_1) \\text{y} f(t,y_2)\\) están en \\(D\\). La constante \\(L\\) es llamada constante de Lipschitz para \\(f\\).\n\n\nDefinición 4.2 Se dice que un conjunto \\(D \\subset \\mathbb{R}^2\\) es convexo si para cualesquiera \\(f(t,y_1), f(t,y_2) \\in D\\), entonces \\(((1-\\lambda)t_1 + \\lambda t_2, (1-\\lambda)y_1 + \\lambda y_2)\\) también pertenece a \\(D\\) para cada \\(\\lambda \\in[0,1]\\).\n\nEn términos geométricos, la Definición 4.2 establece que un conjunto es convexo siempre que, para cualesquiera dos puntos dentro del conjunto, todo el segmento recto entre ellos también pertenezca al conjunto Figura 4.1.\n\n\n\n\n\n\nFigura 4.1: Ejemplo geométrico de un conjunto convexo y no convexo (Burden y Faires 2010).\n\n\n\n\nTeorema 4.1 Supongamos que \\(f(t, y)\\) está definida en un conjunto convexo \\(D \\in \\mathbb{R}2\\). Si existe una constante \\(L &gt; 0\\) con \\[\n\\left|\\dfrac{\\partial f}{\\partial y}(t,y) \\right| \\leq L, \\quad \\text{para todo} (t,y)\\in D,\n\\tag{4.1}\\]\nentonces \\(f\\) satisface una condición de Libschitz en \\(D\\) en la variable \\(y\\) con una constante de Libschitz \\(L\\).\n\nComo se mostrará en el siguiente teorema, suele ser de gran interés determinar si la función involucrada en un problema de valor inicial satisface una condición de Lipschitz en su segunda variable, y la condición Ecuación 4.1 suele ser más fácil de aplicar que la definición. Cabe destacar, sin embargo, que el Teorema Teorema 4.1 solo proporciona condiciones suficientes para que se cumpla una condición de Lipschitz.\n\nTeorema 4.2 Supóngase que \\(D = \\{(t, y) | a \\leq t \\leq b y  -\\infty &lt; y &lt; \\infty \\}\\) y que \\(f (t, y)\\) es continua en \\(D\\). Si \\(f\\) satisface una condición de Lipschitz en \\(D\\) en la variable \\(y\\), entonces el problema del valor inicial \\[\ny'(t)= f(t,y), \\quad a\\leq t \\leq b, \\quad y(a) = \\alpha,\n\\]\ntiene una solución única \\(y(t)\\) para \\(a\\leq t \\leq b\\).\n\n\n\n\n\n\n\nEjemplo\n\n\n\n\n\nUse el teorema Teorema 4.2 para mostrar que hay una única solución al problema de valor inicial: \\[\ny'(t)= 1 + t\\sin(ty), \\quad 0\\leq t \\leq 2, \\quad y(0) = 0.\n\\] Solución: Mantieniendo a \\(t\\) constante y usando el Teorema de valor medio a la función \\[\nf(t,y) = 1 + t\\sin(ty),\n\\] notamos que cuando \\(y_1&lt;y_2\\), un número \\(\\xi\\) existe en \\((y_1,y_2)\\) tal que: \\[\n\\dfrac{f(t,y_2)-f(t,y_1)}{y_2-y_1} = \\dfrac{\\partial}{\\partial y} f(t,\\xi) = t^2\\cos(\\xi t).\n\\] De este modo: \\[\n|f(t,y_2)-f(t,y_1)| = |y_2-y_1||t^2\\cos(\\xi t)| \\leq 4|y_2-y_1|,\n\\] y \\(f\\) satisface una condición de Lipschitz en la variable y con constante de Lipschitz \\(L = 4\\). Además, \\(f(t, y)\\) es continua cuando \\(0 ≤ t ≤ 2\\) y \\(−∞ &lt; y &lt; ∞\\), por lo que el Teorema 4.2 implica que existe una solución única para este problema de valor inicial.\n\n\n\n\n\n\n\n\nBurden, Richard L., y J. Douglas Faires. 2010. «Numerical Analysis». En Numerical Analysis, 9.ª ed., 259-64. Boston, USA: Brooks Cole.",
    "crumbs": [
      "Preliminares",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Problemas de valores iniciales</span>"
    ]
  },
  {
    "objectID": "initial_values.html#problemas-bien-plantedos",
    "href": "initial_values.html#problemas-bien-plantedos",
    "title": "5  Problemas de valor inicial",
    "section": "5.1 Problemas bien plantedos",
    "text": "5.1 Problemas bien plantedos\nAhora que hemos abordado, hasta cierto punto, la cuestión de cuándo los problemas de valor inicial tienen soluciones únicas, podemos pasar a la segunda consideración importante: cuándo aproximar la solución de un problema de valor inicial. Los problemas de valor inicial obtenidos mediante la observación de fenómenos físicos generalmente solo se aproximan a la situación real, por lo que necesitamos saber si pequeños cambios en el plamteamiento del problema introducen cambios correspondientemente pequeños en la solución.\n\nDefinición 5.3 Se dice que el problema de valor inicial \\[\n\\dfrac{dy}{dt} = f(t,y), \\quad a\\leq t \\leq b, \\quad y(a) = \\alpha,\n\\tag{5.2}\\] es un problema bien planteado si:\n\nExiste una única solución \\(y(t)\\) para el problema, y\nExisten constantes \\(ε_0 &gt; 0\\) y \\(k &gt; 0\\) tales que para cualquier \\(ε\\), con \\(ε_0 &gt; ε &gt; 0\\), siempre que \\(δ(t)\\) sea continua con \\(|δ(t)| &lt; ε\\) para todo \\(t\\) en \\([a, b]\\), y cuando \\(|δ_0| &lt; ε\\), el problema del valor inicial \\[\n\\dfrac{dz}{dt} = f(t,z) + δ(t), \\quad a\\leq t \\leq b, \\quad z(a) = \\alpha + δ_0\n\\tag{5.3}\\] tenga una única solución \\(z(t)\\) que satisface: \\[\n|z(t)-y(t)| &lt; k\\epsilon \\quad \\forall t \\in[a,b]\n\\]\n\n\nEl problema especificado por al Ecuación 5.3 se denomina problema perturbado asociado al problema original Ecuación 5.2. Se asume la posibilidad de que se introduzca un error en el planteamiento de la ecuación diferencial, así como la presencia de un error \\(δ_0\\) en la condición inicial.\nLos métodos numéricos siempre se centrarán en la solución de un problema perturbado, ya que cualquier error de redondeo introducido en la representación perturba el problema original. A menos que el problema original esté bien planteado, hay pocas razones para esperar que la solución numérica de un problema perturbado se aproxime con precisión a la solución del problema original.\n\nTeorema 5.3 Supongamos \\(D = \\{(t, y) | a \\leq t \\leq b \\quad y \\quad  -\\infty &lt; y &lt; \\infty \\}\\). Si \\(f\\) es continua y satisface una condición de Lipschitz en la variable \\(y\\) en el conjunto \\(D\\), entonces el problema de valor inicial \\[\n\\dfrac{dy}{dt} = f(t,y), \\quad a\\leq t \\leq b, \\quad y(a) = \\alpha\n\\] es bien planteado.",
    "crumbs": [
      "Preliminares",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Problemas de valor inicial</span>"
    ]
  },
  {
    "objectID": "partial_diff_eq.html#ecuación-diferencial-parcial-lineal",
    "href": "partial_diff_eq.html#ecuación-diferencial-parcial-lineal",
    "title": "3  Ecuaciones diferenciales parciales",
    "section": "3.1 Ecuación diferencial parcial lineal",
    "text": "3.1 Ecuación diferencial parcial lineal\nSi dejamos que \\(u\\) denote la variable dependiente y que \\(x\\) e \\(y\\) representen las variables independientes, entonces la forma general de una ecuación diferencial parcial lineal de segundo orden está dada por:\n\\[\nA \\dfrac{\\partial^2 u}{\\partial x^2} + B \\dfrac{\\partial^2 u}{\\partial x \\, \\partial y} + C \\dfrac{\\partial^2 u}{\\partial y^2} + D \\dfrac{\\partial u}{\\partial x} + E \\dfrac{\\partial u}{\\partial y} + F u = G,\n\\tag{3.1}\\]\ndonde los coeficientes \\(A, B, C, \\dots, G\\) son funciones de \\(x\\) e \\(y\\). Cuando \\(G(x, y) = 0\\), la ecuación 3.1 se denomina homogénea; de lo contrario, es no homogénea. Por ejemplo, las ecuaciones lineales:\n\\[\n\\dfrac{\\partial^2 u}{\\partial x^2} + \\dfrac{\\partial^2 u}{\\partial y^2} = 0 \\quad\\text{y} \\quad \\dfrac{\\partial^2 u}{\\partial x^2} - \\dfrac{\\partial u}{\\partial y} = x y\n\\] son homogénea y no homogénea, respectivamente.",
    "crumbs": [
      "Preliminares",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Ecuaciones diferenciales parciales</span>"
    ]
  },
  {
    "objectID": "partial_diff_eq.html#ecuación-diferencial-parcial-lineal-1",
    "href": "partial_diff_eq.html#ecuación-diferencial-parcial-lineal-1",
    "title": "3  Ecuaciones diferenciales parciales",
    "section": "3.2 ECUACIÓN DIFERENCIAL PARCIAL LINEAL",
    "text": "3.2 ECUACIÓN DIFERENCIAL PARCIAL LINEAL\nSi dejamos que $u$ denote la variable dependiente y que \\(x\\) e \\(y\\) representen las variables independientes, entonces la forma general de una ecuación diferencial parcial lineal de segundo orden está dada por:\n\\[\nA \\dfrac{\\partial^2 u}{\\partial x^2} + B \\dfrac{\\partial^2 u}{\\partial x \\, \\partial y} + C \\dfrac{\\partial^2 u}{\\partial y^2} + D \\dfrac{\\partial u}{\\partial x} + E \\dfrac{\\partial u}{\\partial y} + F u = G,\n\\tag{3.1}\\]\ndonde los coeficientes $A, B, C, , \\(G\\) son funciones de \\(x\\) e \\(y\\). Cuando \\(G(x, y) = 0\\), la ecuación Ecuación 3.1 se denomina homogénea; de lo contrario, es no homogénea. Por ejemplo, las ecuaciones lineales:\n\\[\n\\dfrac{\\partial^2 u}{\\partial x^2} + \\dfrac{\\partial^2 u}{\\partial y^2} = 0 \\quad\\text{y} \\quad \\dfrac{\\partial^2 u}{\\partial x^2} - \\dfrac{\\partial u}{\\partial y} = x y\n\\] son homogénea y no homogénea, respectivamente.",
    "crumbs": [
      "Preliminares",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Ecuaciones diferenciales parciales</span>"
    ]
  },
  {
    "objectID": "partial_diff_eq.html#solucion-de-una-pde",
    "href": "partial_diff_eq.html#solucion-de-una-pde",
    "title": "3  Ecuaciones diferenciales parciales",
    "section": "3.2 Solucion de una PDE",
    "text": "3.2 Solucion de una PDE\nUna solución de una ecuación diferencial parcial es una función \\(u(x, y)\\) de dos variables independientes que posee todas las derivadas parciales que aparecen en la ecuación y que satisface dicha ecuación en alguna región del plano \\(xy\\).\nNo es lo habitual examinar los procedimientos para encontrar soluciones generales de ecuaciones diferenciales parciales lineales. No solo porque suele ser difícil obtener una solución general de una EDP lineal de segundo orden, sino que una solución general generalmente no es tan útil en aplicaciones prácticas. Por lo tanto, el enfoque común es el de encontrar soluciones particulares de algunas de las EDPs lineales más importantes, es decir, ecuaciones que aparecen en muchas aplicaciones.",
    "crumbs": [
      "Preliminares",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Ecuaciones diferenciales parciales</span>"
    ]
  },
  {
    "objectID": "partial_diff_eq.html#separación-de-variables",
    "href": "partial_diff_eq.html#separación-de-variables",
    "title": "3  Ecuaciones diferenciales parciales",
    "section": "3.3 Separación de variables",
    "text": "3.3 Separación de variables\nAunque existen varios métodos que pueden intentarse para encontrar soluciones particulares de una EDP lineal, uno de los métodos más comunes se llama método de separación de variables. En este método buscamos una solución particular de la forma de un producto de una función de \\(x\\) y una función de \\(y\\):\n\\[\nu(x, y) = X(x)Y(y).\n\\]\nCon esta suposición, a veces es posible reducir una EDP lineal en dos variables a dos ecuaciones diferenciales ordinarias (ODEs). Para este fin, observamos que:\n\\[\n\\dfrac{\\partial u}{\\partial x} = X'Y, \\quad\n\\dfrac{\\partial u}{\\partial y} = XY', \\quad\n\\dfrac{\\partial^2 u}{\\partial x^2} = X''Y, \\quad\n\\dfrac{\\partial^2 u}{\\partial y^2} = XY'',\n\\]\ndonde las comillas (primes) denotan derivación ordinaria.",
    "crumbs": [
      "Preliminares",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Ecuaciones diferenciales parciales</span>"
    ]
  },
  {
    "objectID": "partial_diff_eq.html#principio-de-superposición",
    "href": "partial_diff_eq.html#principio-de-superposición",
    "title": "3  Ecuaciones diferenciales parciales",
    "section": "3.4 Principio de superposición",
    "text": "3.4 Principio de superposición\n\nTeorema 3.1 Si \\(u_1 , u_2 , \\dots , u_k\\) son soluciones de una ecuación diferencial parcial lineal homogénea, entonces la combinación lineal \\[\nu = c_1u_1 + c_2u_2 + \\dots + c_ku_k\n\\] donde las \\(c_1=1,2,\\dots,k\\) son constantes. Es también una solución.\n\nEL teorema 3.1 se puede entender como siempre que tengamos un conjunto infinito de soluciones \\(u_1, u_2, u_3, \\ldots\\) de una ecuación lineal homogénea, podemos construir otra solución \\(u\\) mediante la serie infinita:\n\\[  \nu = \\sum_{k=1}^{\\infty} c_k u_k,  \n\\]\ndonde las constantes \\(c_i\\), con \\(i = 1, 2, \\ldots\\), son coeficientes.",
    "crumbs": [
      "Preliminares",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Ecuaciones diferenciales parciales</span>"
    ]
  },
  {
    "objectID": "boundary_problems.html#ecuaciones-clásicas",
    "href": "boundary_problems.html#ecuaciones-clásicas",
    "title": "4  Problemas de valores en la frontera",
    "section": "4.1 Ecuaciones clásicas",
    "text": "4.1 Ecuaciones clásicas\nAplicar el método de separación de variables para encontrar soluciones en forma de producto es muy común con las siguientes ecuaciones clásicas de la física matemática:\n\\[  \nk\\frac{\\partial^2 u}{\\partial x^2} = \\frac{\\partial u}{\\partial t}, \\quad k &gt; 0  \n\\tag{4.1}\\]\n\\[  \n\\alpha^2 \\frac{\\partial^2 u}{\\partial x^2} = \\frac{\\partial^2 u}{\\partial t^2}  \n\\tag{4.2}\\]\n\\[  \n\\frac{\\partial^2 u}{\\partial x^2} + \\frac{\\partial^2 u}{\\partial y^2} = 0  \n\\tag{4.3}\\]\no variantes ligeras de estas ecuaciones. Las EDPs 4.1, 4.2 y 4.3 se conocen, respectivamente, como la ecuación del calor unidimensional, la ecuación de onda unidimensional y la forma bidimensional de la ecuación de Laplace. El término “unidimensional” en el caso de las ecuaciones 4.1 y 4.2 se refiere al hecho de que \\(x\\) denota una variable espacial, mientras que \\(t\\) representa el tiempo; “bidimensional” en 4.3 significa que tanto \\(x\\) como \\(y\\) son variables espaciales. Si comparas 4.1-4.3 con la forma lineal en la Definición 3.1 (donde \\(t\\) juega el papel del símbolo \\(y\\)), observarás que la ecuación del calor 4.1 es parabólica, la ecuación de onda 4.2 es hiperbólica y la ecuación de Laplace 4.3 es elíptica.\n\n\n\n\n\n\n\n\n\n\n\n(a) Flujo de calor unidimensional.\n\n\n\n\n\n\n\n\n\n\n\n(b) Cuerda tensada.\n\n\n\n\n\n\n\nFigura 4.1: Aplicaciones de las ecuaciones 4.1 y 4.2 (Zill y Cullen 2008).",
    "crumbs": [
      "Preliminares",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Problemas de valores en la frontera</span>"
    ]
  },
  {
    "objectID": "partial_diff_eq.html",
    "href": "partial_diff_eq.html",
    "title": "3  Ecuaciones diferenciales parciales",
    "section": "",
    "text": ":::",
    "crumbs": [
      "Preliminares",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Ecuaciones diferenciales parciales</span>"
    ]
  },
  {
    "objectID": "partial_diff_eq.html#clasificación-de-ecuaciones",
    "href": "partial_diff_eq.html#clasificación-de-ecuaciones",
    "title": "3  Ecuaciones diferenciales parciales",
    "section": "3.5 Clasificación de ecuaciones",
    "text": "3.5 Clasificación de ecuaciones\nUna ecuación diferencial parcial lineal de segundo orden con dos variables independientes y coeficientes constantes puede clasificarse en uno de tres tipos. Esta clasificación depende únicamente de los coeficientes de las derivadas de segundo orden. Por supuesto, asumimos que al menos uno de los coeficientes \\(A\\), \\(B\\) o \\(C\\) es distinto de cero.\n\nDefinición 3.1 La ecuación diferencial parcial lineal de segundo orden \\[\nA \\dfrac{\\partial^2 u}{\\partial x^2} + B \\dfrac{\\partial^2 u}{\\partial x \\, \\partial y} + C \\dfrac{\\partial^2 u}{\\partial y^2} + D \\dfrac{\\partial u}{\\partial x} + E \\dfrac{\\partial u}{\\partial y} + F u = 0,\n\\] donde \\(A,B,C,D,F\\) son constantes reales, se dice que es:\n\nHiperbólica si \\(\\quad B^2-4AC&gt;0\\),\nParabólica si \\(\\quad B^2-4AC=0\\),\nElíptica si \\(\\quad B^2-4AC&lt;0\\).",
    "crumbs": [
      "Preliminares",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Ecuaciones diferenciales parciales</span>"
    ]
  },
  {
    "objectID": "boundary_problems.html#condiciones-iniciales",
    "href": "boundary_problems.html#condiciones-iniciales",
    "title": "4  Problemas de valores en la frontera",
    "section": "4.2 Condiciones iniciales",
    "text": "4.2 Condiciones iniciales\nDado que las soluciones de las ecuaciones 4.1 y 4.2 dependen del tiempo \\(t\\), es posible especificar lo que ocurre en \\(t = 0\\); es decir, establecer condiciones iniciales (CI). Si \\(f(x)\\) representa la distribución inicial de temperatura en la barra mostrada en la Figura 4.1 (a), entonces una solución \\(u(x, t)\\) de 4.1 debe satisfacer la condición inicial única \\(u(x, 0) = f(x), \\quad 0 &lt; x &lt; L\\).\nPor otro lado, para una cuerda vibrante podemos especificar tanto su desplazamiento inicial (o forma) \\(f(x)\\) como su velocidad inicial \\(g(x)\\). En términos matemáticos, buscamos una función \\(u(x, t)\\) que satisfaga 4.2 y las dos condiciones iniciales: \\[\nu(x, 0) = f(x), \\quad \\left. \\frac{\\partial u}{\\partial t} \\right|_{t=0} = g(x), \\quad 0 &lt; x &lt; L.\n\\]\nPor ejemplo, la cuerda podría ser tensada, como se muestra en la Figura 4.1 (b), y liberada desde el reposo \\((g(x)=0)\\).",
    "crumbs": [
      "Preliminares",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Problemas de valores en la frontera</span>"
    ]
  }
]