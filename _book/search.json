[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Estimación de la temperatura con la ecuacion del Bio-Calor usando DeepONet",
    "section": "",
    "text": "Resumen\nAquí irá el resumen de la tesis.",
    "crumbs": [
      "Resumen"
    ]
  },
  {
    "objectID": "pinns.html#comparación-con-redes-neuronales-tradicionales",
    "href": "pinns.html#comparación-con-redes-neuronales-tradicionales",
    "title": "2  Physic Informed Neural Networks (PINNs)",
    "section": "2.1 Comparación con Redes Neuronales Tradicionales",
    "text": "2.1 Comparación con Redes Neuronales Tradicionales\nMientras que las redes neuronales tradicionales dependen exclusivamente de grandes volúmenes de datos etiquetados para su entrenamiento (Karniadakis et al. 2021), las PINNs integran el conocimiento físico como parte esencial de su arquitectura (Blechschmidt y Ernst 2021). Esta diferencia clave permite a las PINNs generar soluciones físicamente consistentes incluso con datos escasos, evitando el sobreajuste común en enfoques puramente basados en datos. Otra ventaja significativa de las PINNs es su naturaleza mesh-free, que contrasta con los métodos numéricos tradicionales como FEM o FDM que requieren discretización espacial. Sin embargo, el entrenamiento de PINNs puede ser más desafiante debido a la necesidad de optimizar múltiples objetivos simultáneamente (ajuste a datos y cumplimiento de leyes físicas) (Blechschmidt y Ernst 2021; Karniadakis et al. 2021).",
    "crumbs": [
      "Redes neuronales",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Physic Informed Neural Networks (PINNs)</span>"
    ]
  },
  {
    "objectID": "deeponet.html#arquitectura",
    "href": "deeponet.html#arquitectura",
    "title": "3  DeepONet",
    "section": "3.1 Arquitectura",
    "text": "3.1 Arquitectura\nLa arquitectura de DeepONet está compuesta por dos redes principales: la red de branch y la red de trunk. La red branch procesa las evaluaciones discretas de la función de entrada (por ejemplo, condiciones iniciales o de frontera), mientras que la red trunk recibe como entrada los puntos del dominio donde se desea evaluar la función de salida. La salida final se obtiene mediante el producto punto de los vectores generados por ambas redes, lo que permite representar operadores complejos con alta generalización a nuevos datos (Lu et al. 2021).\n\n\n\n\n\n\nFigura 3.1: Ilustraciones del planteamiento del problema y arquitectura DeepONet que conducen a una buena generalización. a) Para que la red aprenda un operador \\(G : u \\rightarrow G(u)\\) se necesitan dos entradas \\([u(x_1), u(x_2), ..., u(x_m)]\\) e \\(y\\). b) Ilustración de los datos de entrenamiento. Para cada función de entrada \\(u\\), se requiere el mismo número de evaluaciones en los mismos sensores dispersos \\(x_1, x_2, ..., x_m\\). Sin embargo, no se impone ninguna restricción sobre el número ni las ubicaciones para la evaluación de las funciones de salida. c) La DeepONet stacked se inspira en el Teorema 1 y consta de una red Trunk y \\(p\\) redes Branch apiladas. La red construida en el Teorema 1 es una DeepONet stacked formada al elegir la red Trunk como una red de una capa de ancho \\(p\\) y cada red Branch como una red de una capa oculta de ancho \\(n\\). d) La red DeepONet unstacked se inspira en el Teorema 2 y consta de una red Trunk y una red Branch. Una red DeepONet unstacked puede considerarse como una red DeepONet stacked, en la que todas las redes Branch comparten el mismo conjunto de parámetros (Lu et al. 2021).",
    "crumbs": [
      "Redes neuronales",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>DeepONet</span>"
    ]
  },
  {
    "objectID": "deeponet.html#comparación-con-una-pinn",
    "href": "deeponet.html#comparación-con-una-pinn",
    "title": "3  DeepONet",
    "section": "3.2 Comparación con una PINN",
    "text": "3.2 Comparación con una PINN\nEn contraste con una red PINN convencional (Physics-Informed Neural Network), que resuelve una instancia específica de una ecuación diferencial para un conjunto dado de condiciones, DeepONet aprende el operador general que resuelve muchas instancias a la vez. Mientras que una PINN debe ser reentrenada para cada nuevo problema, DeepONet, una vez entrenado, puede predecir soluciones rápidamente para múltiples condiciones nuevas. Esto lo hace especialmente eficiente en aplicaciones donde se requiere realizar inferencias repetidas, como en control o diseño inverso (Kumar et al. 2024).",
    "crumbs": [
      "Redes neuronales",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>DeepONet</span>"
    ]
  },
  {
    "objectID": "PBHE.html",
    "href": "PBHE.html",
    "title": "Ecuación del Bio-Calor",
    "section": "",
    "text": "La ecuación del bio-calor, formulada por Pennes (1948), surgió de su estudio pionero “Analysis of Tissue and Arterial Blood Temperatures in the Resting Human Forearm”. Publicado en el Journal of Applied Physiology, este trabajo fue el primero en cuantificar la interacción entre la temperatura arterial y tisular en humanos. Pennes combinó principios termodinámicos con mediciones experimentales en el antebrazo, estableciendo un modelo matemático que relacionaba el flujo sanguíneo, la producción metabólica de calor y la conducción térmica en tejidos.\n\n\n\n\n\n\nFigura 1: a) Posición del brazo derecho (vista superior). La linea horizontal II indica el nivel de la figura c). b) Posición del brazo derecho (vista lateral). c)Sección transversal anatómica del antebrazo en el nivel II (Pennes 1948).\n\n\n\nEl modelo de Pennes simplificó la complejidad biológica al asumir un flujo sanguíneo uniforme y una transferencia de calor proporcional a la diferencia entre la temperatura arterial y la tisular. Aunque posteriores investigaciones refinaron sus supuestos, su ecuación sigue siendo un referente en bioingeniería térmica. Su trabajo no solo sentó las bases para aplicaciones clínicas, como la hipertermia oncológica, sino que también inspiró avances en el estudio de la termorregulación humana y el diseño de dispositivos médicos.\n\n\n\n\n\nPennes, H. H. 1948. «Analysis of Tissue and Arterial Blood Temperatures in the Resting Human Forearm». Journal of Applied Physiology 1 (2): 93-122. https://doi.org/10.1152/jappl.1948.1.2.93.",
    "crumbs": [
      "Ecuación del Bio-Calor"
    ]
  },
  {
    "objectID": "ecuacion.html#versión-reducida-adimensionalizada",
    "href": "ecuacion.html#versión-reducida-adimensionalizada",
    "title": "4  Forma de la ecuación",
    "section": "4.1 Versión reducida (adimensionalizada)",
    "text": "4.1 Versión reducida (adimensionalizada)\nMediante escalamiento: \\[\\begin{equation}\nT' = T - T_a \\qquad \\theta = \\dfrac{T'}{T_M - T_a} \\qquad X = \\dfrac{x}{L_0} \\qquad \\tau = \\dfrac{t}{t_f}\n\\end{equation}\\]\n\n\n\nSímbolo\nDescripción\nUnidades\n\n\n\n\n\\(L_0\\)\nLongitud característica del dominio\n\\(m\\)\n\n\n\\(t_f\\)\nTiempo final de simulación\n\\(s\\)\n\n\n\nse obtiene:\n\\[\\begin{equation}\n\\partial_{\\tau} \\theta = a_1 \\partial_{XX} \\theta - a_2 W \\theta + a_3\n\\end{equation}\\]\nParámetros adimensionales:\n- \\(a_1 = \\frac{t_f}{\\alpha L_0^2}\\) (difusividad térmica \\(\\alpha = \\frac{k_{\\text{eff}}}{\\rho c}\\)).\n- \\(a_2 = \\frac{t_f c_b}{\\rho c}\\).\n- \\(a_3 = \\frac{t_f Q}{\\rho c (T_M - T_a)}\\).\n- \\(W = \\rho_b \\omega_b\\): Tasa volumétrica de perfusión (kg/m³·s).",
    "crumbs": [
      "Ecuación del Bio-Calor",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Forma de la ecuación</span>"
    ]
  },
  {
    "objectID": "ecuacion.html#condiciones-de-uso-adecuadas",
    "href": "ecuacion.html#condiciones-de-uso-adecuadas",
    "title": "4  Forma de la ecuación",
    "section": "4.2 Condiciones de uso adecuadas",
    "text": "4.2 Condiciones de uso adecuadas\n\nTejidos homogéneos: Aproximación válida para regiones con propiedades térmicas uniformes.\n\nPerfusión sanguínea constante: Supone flujo sanguíneo estable en el dominio.\n\nAplicaciones clínicas: Hipertermia, crioterapia y modelado térmico en terapias oncológicas.",
    "crumbs": [
      "Ecuación del Bio-Calor",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Forma de la ecuación</span>"
    ]
  },
  {
    "objectID": "ejemplos.html#aplicaciones-recientes-de-la-ecuación-del-bio-calor",
    "href": "ejemplos.html#aplicaciones-recientes-de-la-ecuación-del-bio-calor",
    "title": "5  Modelado del Bio-Calor en Hipertermia",
    "section": "5.1 Aplicaciones recientes de la ecuación del bio-calor",
    "text": "5.1 Aplicaciones recientes de la ecuación del bio-calor\nQuintero et al. (2017) desarrollan un modelo basado en ecuaciones diferenciales parciales que integra la ecuación del bio-calor y la ley de Arrhenius para estimar el daño térmico en tratamientos de hipertermia superficial. Utilizan el método de líneas para resolver el sistema y plantean un problema de optimización que busca maximizar el daño al tejido tumoral minimizando el daño colateral. Su trabajo demuestra cómo la modelación matemática puede guiar estrategias terapéuticas más seguras y eficaces.\nDutta y Rangarajan (2018) presentan una solución analítica cerrada en dos dimensiones para la ecuación del bio-calor, considerando modelos de conducción tanto de tipo Fourier como no-Fourier. Mediante el uso de la transformada de Laplace, analizan la influencia de parámetros fisiológicos como la perfusión sanguínea y el tiempo de relajación térmica sobre la evolución de la temperatura. Su investigación aporta una base teórica sólida para comprender la propagación térmica en tejidos vivos durante la hipertermia terapéutica.\nYang et al. (2014) propone una estrategia numérica para resolver problemas inversos de conducción térmica en tejidos biológicos multicapa, utilizando un enfoque en diferencias finitas y el concepto de tiempo futuro. El estudio se enfoca en predecir las condiciones de frontera necesarias para generar distribuciones de temperatura deseadas. La implementación de este método permite estimar parámetros relevantes en tiempo real, lo cual resulta esencial para el control térmico preciso en procedimientos médicos no invasivos como la hipertermia localizada.",
    "crumbs": [
      "Ecuación del Bio-Calor",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Modelado del Bio-Calor en Hipertermia</span>"
    ]
  },
  {
    "objectID": "estudio_caso.html",
    "href": "estudio_caso.html",
    "title": "Estudio de caso",
    "section": "",
    "text": "La Organización Mundial de la Salud (2022) en su página web define Cáncer como:\n\n«Cáncer» es un término genérico utilizado para designar un amplio grupo de enfermedades que pueden afectar a cualquier parte del organismo; también se habla de «tumores malignos» o «neoplasias malignas». Una característica definitoria del cáncer es la multiplicación rápida de células anormales que se extienden más allá de sus límites habituales y pueden invadir partes adyacentes del cuerpo o propagarse a otros órganos, en un proceso que se denomina «metástasis». La extensión de las metástasis es la principal causa de muerte por la enfermedad.\n\nPor su parte Instituto Nacional del Cáncer (2021) aporta lo siguiente:\n\nEs posible que el cáncer comience en cualquier parte del cuerpo humano, formado por billones de células. En condiciones normales, las células humanas se forman y se multiplican (mediante un proceso que se llama división celular) para formar células nuevas a medida que el cuerpo las necesita. Cuando las células envejecen o se dañan, mueren y las células nuevas las reemplazan. A veces el proceso no sigue este orden y las células anormales o células dañadas se forman y se multiplican cuando no deberían. Estas células tal vez formen tumores, que son bultos de tejido. Los tumores son cancerosos (malignos) o no cancerosos (benignos).\n\n\n\n\n\n\n\nFigura 1: Una célula de cáncer de seno que se multiplica (Instituto Nacional del Cáncer 2021).\n\n\n\nÉsta enfermedad es la principal causa de muerte a nivel mundial, solo en 2020 arrebató casi 10 millones de vidas y según datos de Organización Mundial de la Salud (2022) los cánceres más comunes en 2020 fueron:\n\nDe mama (2.26 millones de casos)\nDe pulmón (2.21 millones de casos)\nDe colon (1.93 millones de casos)\nDe próstata (1.41 millones de casos)\nDe piel (distinto del melanoma) (1.20 millones de casos)\nGástrico (1.09 millones de casos)\n\nEs ante este panorama que distintos tratamientos surgen con el objetivo de erradicar la enfermedad siempre que se tenga una detección oportuna. Uno de dichos tratamientos es la hipertermia, según en el National Cancer Institute (2021) es un método que consiste en calentar el tejido corporal hasta los 39-45 °C para ayudar a erradicar células cancerígenas con pequeñas o nulas lesiones en el tejido sano. La hipertermia también es llamada terapia térmica o termoterapia.\nUno de los principales retos de este tratamiento es la creación de un modelo óptimo que se adecue al comportamiento de la transferencia de calor que se hace a los tejidos con el fin de dañar únicamente el área en el que se encuentran las célular cancerígenas, es por ello que los modelos de integencia artificial y más precisamente las PINN’s (aqui irá una cita) surgen como posible solución a este reto.\nEl presente estudio utilizó como punto de partida el trabajo realizado por Alessio Borgi (2023) para modelar el calentamiento del tejido corporal usando la ecuación del Bio-Calor en dos dimensiones.\n\n\n\n\n\nAlessio Borgi, Alessandro De Luca, Eugenio Bugli. 2023. «BioHeat PINNs: Temperature Estimation with Bio-Heat Equation using Physics-Informed Neural Networks». https://github.com/alessioborgi/BioHeat_PINNs/tree/main?tab=readme-ov-file#bioheat-pinns-temperature-estimation-with-bio-heat-equation-using-physics-informed-neural-networks.\n\n\nInstituto Nacional del Cáncer. 2021. «¿Qué es el cáncer?» https://www.cancer.gov/espanol/cancer/naturaleza/que-es.\n\n\nNational Cancer Institute. 2021. «Hyperthermia to Treat Cancer». https://www.cancer.gov/about-cancer/treatment/types/hyperthermia.\n\n\nOrganización Mundial de la Salud. 2022. «Cáncer». https://www.who.int/es/news-room/fact-sheets/detail/cancer.",
    "crumbs": [
      "Estudio de caso"
    ]
  },
  {
    "objectID": "metodologia.html#aportaciones-del-modelo",
    "href": "metodologia.html#aportaciones-del-modelo",
    "title": "6  Metodología",
    "section": "6.1 Aportaciones del modelo",
    "text": "6.1 Aportaciones del modelo\nYa que se parte del trabajo de Alessio Borgi (2023), se examinó que dos de los puntos a mejorar de la red neuronal que plantearon son:\n\nDesarrollar nuevas arquitecturas para la red neuronal y explorar nuevas configuraciones\nCombinar las fortalezas de los algoritmos de optimización Adam y L-BFGS para mejorar la velocidad de convergencia y la precisión\n\nTenindo los anteriores puntos en cuenta, se procedió a abordarlos e implementarlos dentro del diseño del modelo.",
    "crumbs": [
      "Estudio de caso",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Metodología</span>"
    ]
  },
  {
    "objectID": "metodologia.html#diseño-del-modelo",
    "href": "metodologia.html#diseño-del-modelo",
    "title": "6  Metodología",
    "section": "6.2 Diseño del modelo",
    "text": "6.2 Diseño del modelo\nEl lenguaje seleccionado fué Python, a su vez el código se basa enteramente en la librería Deepxde creada por Lu et al. (2021) la cual está directamente enfocada a resolver ecuaciones diferenciales, se usó además como backend tensorflow_compat_v1 siendo su elección debida únicamente a la familiarización previa que se tenía con ella. Finalmente el entorno donde se programó y optimizó el código fué en Google Colab ya que la potencia de cómputo ofrecida por la plataforma era necesaria para ejecutar el modelo.",
    "crumbs": [
      "Estudio de caso",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Metodología</span>"
    ]
  },
  {
    "objectID": "metodologia.html#implementación-del-modelo",
    "href": "metodologia.html#implementación-del-modelo",
    "title": "6  Metodología",
    "section": "6.3 Implementación del modelo",
    "text": "6.3 Implementación del modelo\nUna vez creado el código que resuelve la ecuación del Bio-Calor, se ajustaron los hiperparámetros tales como cantidad de épocas de entrenamiento, el ratio de aprendizaje, la función de activación y el inicializador en base al trabajo de Alessio Borgi (2023).",
    "crumbs": [
      "Estudio de caso",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Metodología</span>"
    ]
  },
  {
    "objectID": "metodologia.html#evaluación-del-modelo",
    "href": "metodologia.html#evaluación-del-modelo",
    "title": "6  Metodología",
    "section": "6.4 Evaluación del modelo",
    "text": "6.4 Evaluación del modelo\nSe llevó a cabo una evaluación del modelo al darle como entrada un conjunto de datos que no había visto y posteriormente obtener como salida sus predicciones, con ellas se elaboraron gráficas claras y detalladas de su pronóstico en el intervalo de tiempo y espacio especificados.",
    "crumbs": [
      "Estudio de caso",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Metodología</span>"
    ]
  },
  {
    "objectID": "metodologia.html#comparación-de-resultados",
    "href": "metodologia.html#comparación-de-resultados",
    "title": "6  Metodología",
    "section": "6.5 Comparación de resultados",
    "text": "6.5 Comparación de resultados\nLos resultados obtenidos de la evaluación del modelo fueron comparados con los del trabajo de Alessio Borgi (2023) para determinar su eficacia predictiva relativa. Se analizaron las fortalezas y debilidades del modelo en función de su desempeño en la predicción de las variables de interés.",
    "crumbs": [
      "Estudio de caso",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Metodología</span>"
    ]
  },
  {
    "objectID": "metodologia.html#análisis-y-conclusión",
    "href": "metodologia.html#análisis-y-conclusión",
    "title": "6  Metodología",
    "section": "6.6 Análisis y conclusión",
    "text": "6.6 Análisis y conclusión\nFinalmente, se realizó un análisis detallado de los resultados obtenidos para extraer conclusiones significativas. Se proporcionaron recomendaciones basadas en los hallazgos del estudio, lo que permitió establecer un marco para interpretaciones analíticas profundas y recomendaciones bien fundamentadas en la sección de conclusiones del estudio.\nEste enfoque metodológico proporcionó una base sólida para los resultados obtenidos, asegurando la integridad y la calidad del análisis realizado en el estudio.",
    "crumbs": [
      "Estudio de caso",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Metodología</span>"
    ]
  },
  {
    "objectID": "predicciones.html",
    "href": "predicciones.html",
    "title": "7  Predicciones del modelo",
    "section": "",
    "text": "Conforme se ha referido previamente, se creó el modelo utilizando Deepxde como base. Resulta relevante descatacar que se empleó la versión 1.10.1 de dicha librería. A continuación se presenta el código fuente de la red neuronal\n\n\nCódigo\nimport deepxde as dde\nimport numpy as np\nimport tensorflow as tf\n\n# ------------------------------------------------------------------------------\n# Constants and Parameters\n# ------------------------------------------------------------------------------\n\n# Backend and seed\ndde.backend.set_default_backend(\"tensorflow.compat.v1\")\ndde.config.set_random_seed(123)\n\n# Physical parameters\nheat_coefficient = 1.0\np = 1050\nc = 3639\nkeff = 5\ntf = 1800\nL0 = 0.05\ncb = 3825\nQ = 0\nTM = 45\nTa = 37\nalpha = p * c / keff\n\n# Dimensionless coefficients\na1 = tf / (alpha * L0**2)\na2 = tf * cb / (p * c)\na3 = (tf * Q) / (p * c * (TM - Ta))\n\n# Domain boundaries\nx_initial, x_boundary = 0.0, 1.0\ny_initial, y_boundary = 0.0, 1.0\nt_initial, t_final = 0.0, 1.0\n\n# Dataset configuration\npts_dom = 10\npts_bc = 20\npts_ic = 60\nnum_test = 25\n\n# Sensor grid and function space\nnum_sensors = 4\nsize_cov_matrix = 40\n\n# Network architecture\nwidth_net = 20\nlen_net = 3\nAF = \"elu\"\nk_initializer = \"Glorot normal\"\n\n# Training parameters\nnum_iterations = 1000\nlearning_rate = 2e-3\ndecay_rate = 0.05\ndecay_steps = 1000\n\n# ------------------------------------------------------------------------------\n# Geometry and Time Domain\n# ------------------------------------------------------------------------------\n\nspatial_domain = dde.geometry.Rectangle([x_initial, y_initial],\n                                        [x_boundary, y_boundary])\ntime_domain = dde.geometry.TimeDomain(t_initial, t_final)\ngeomtime = dde.geometry.GeometryXTime(spatial_domain, time_domain)\n\n# ------------------------------------------------------------------------------\n# PDE and Conditions\n# ------------------------------------------------------------------------------\n\ndef initial_condition(X):\n    return 0\n\ndef heat_equation(func, u, coords):\n    u_t = dde.grad.jacobian(u, func, i=0, j=2)\n    u_xx = dde.grad.hessian(u, func, i=0, j=0)\n    u_yy = dde.grad.hessian(u, func, i=1, j=1)\n    return a1 * u_t - (u_xx + u_yy) + a2 * u\n\ndef zero_value(X):\n    return 0\n\ndef time_value(X):\n    return X[:, 2]\n\ndef is_on_vertex(x):\n    vertices = np.array([[x_initial, y_initial],\n                         [x_boundary, y_initial],\n                         [x_initial, y_boundary],\n                         [x_boundary, y_boundary]])\n    return any(np.allclose(x, v) for v in vertices)\n\ndef is_initial(X, on_initial):\n    return on_initial and np.isclose(X[2], t_initial)\n\ndef left_boundary(X, on_boundary):\n    spatial = X[0:2]\n    t = X[2]\n    return (\n        on_boundary \n        and np.isclose(spatial[0], x_initial) \n        and not np.isclose(t, t_initial) \n        and not is_on_vertex(spatial)\n    )\n\ndef right_boundary(X, on_boundary):\n    spatial = X[0:2]\n    t = X[2]\n    return (\n        on_boundary \n        and np.isclose(spatial[0], x_boundary) \n        and not np.isclose(t, t_initial) \n        and not is_on_vertex(spatial)\n    )\n\ndef up_low_boundary(X, on_boundary):\n    spatial = X[0:2]\n    t = X[2]\n    return (on_boundary \n    and (np.isclose(spatial[1], y_initial) \n    or np.isclose(spatial[1], y_boundary)) \n    and not np.isclose(t, t_initial) \n    and not is_on_vertex(spatial)\n    )\n\n# Initial and boundary conditions\nic = dde.icbc.IC(geomtime, initial_condition, is_initial)\nleft_bc = dde.icbc.DirichletBC(geomtime, \n                                zero_value, left_boundary)\nright_bc = dde.icbc.NeumannBC(geomtime,\n                                time_value, right_boundary)\nup_low_bc = dde.icbc.NeumannBC(geomtime, \n                                zero_value, up_low_boundary)\n\n# ------------------------------------------------------------------------------\n# Dataset Construction\n# ------------------------------------------------------------------------------\n\npde_data = dde.data.TimePDE(\n    geomtime,\n    heat_equation,\n    [ic, left_bc, right_bc, up_low_bc],\n    num_domain=pts_dom,\n    num_boundary=pts_bc,\n    num_initial=pts_ic \n)\n\n# ------------------------------------------------------------------------------\n# Sensor Points and Function Space\n# ------------------------------------------------------------------------------\n\nside = np.linspace(x_initial, x_boundary, num_sensors + 1)\nx, y = np.meshgrid(side, side, indexing='xy')\nsensor_pts = np.stack([x.ravel(), y.ravel()], axis=1)\n\nfs = dde.data.function_spaces.GRF2D(N=size_cov_matrix, \n                                    interp=\"linear\")\n\ndata = dde.data.PDEOperatorCartesianProd(\n    pde_data,\n    fs,\n    sensor_pts,\n    num_function=(num_sensors + 1)**2,\n    function_variables=[0, 1],\n    num_test=num_test\n)\n\n# ------------------------------------------------------------------------------\n# Network Definition\n# ------------------------------------------------------------------------------\n\nbranch_layers = [(num_sensors + 1)**2] + len_net * [width_net]\ntrunk_layers = [3] + len_net * [width_net]\n\nnet = dde.nn.DeepONetCartesianProd(\n    branch_layers,\n    trunk_layers,\n    activation=AF,\n    kernel_initializer=k_initializer\n)\n\n# ------------------------------------------------------------------------------\n# Model Compilation and Training\n# ------------------------------------------------------------------------------\n\nmodel = dde.Model(data, net)\nmodel.compile(\"adam\", lr=learning_rate, decay=(\"inverse time\", decay_steps, decay_rate))\nlosshistory, train_state = model.train(iterations=num_iterations)\n\n# Fine-tuning with LBFGS optimizer\nmodel.compile(\"L-BFGS\")\nlosshistory, train_state = model.train()\n\n\n2025-05-20 19:18:35.745165: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n2025-05-20 19:18:35.801800: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n2025-05-20 19:18:35.802616: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\nTo enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2025-05-20 19:18:36.657787: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\nUsing backend: tensorflow.compat.v1\nOther supported backends: tensorflow, pytorch, jax, paddle.\npaddle supports more examples now and is recommended.\n\n\nWARNING:tensorflow:From /home/damian/.local/lib/python3.8/site-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\nInstructions for updating:\nnon-resource variables are not supported in the long term\nSetting the default backend to \"tensorflow.compat.v1\". You can change it in the ~/.deepxde/config.json file or export the DDE_BACKEND environment variable. Valid options are: tensorflow.compat.v1, tensorflow, pytorch, jax, paddle (all lowercase)\nCompiling model...\nBuilding DeepONetCartesianProd...\n'build' took 0.106258 s\n\n\n\n/home/damian/.local/lib/python3.8/site-packages/deepxde/nn/tensorflow_compat_v1/deeponet.py:549: UserWarning:\n\n`tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n\n/home/damian/.local/lib/python3.8/site-packages/deepxde/nn/tensorflow_compat_v1/deeponet.py:556: UserWarning:\n\n`tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n\n/home/damian/.local/lib/python3.8/site-packages/deepxde/nn/tensorflow_compat_v1/deeponet.py:570: UserWarning:\n\n`tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n\n\n\n'compile' took 16.739955 s\n\n\n\n2025-05-20 19:18:55.129370: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:375] MLIR V1 optimization pass is not enabled\n\n\nTraining model...\n\nStep      Train loss                                            Test loss                                             Test metric\n0         [2.57e+00, 4.03e-01, 4.13e-01, 6.71e-01, 1.05e+00]    [1.57e+00, 1.57e-01, 3.45e-01, 5.19e-01, 3.07e-01]    []  \n1000      [3.97e-03, 3.15e-03, 3.81e-04, 2.63e-02, 1.86e-04]    [6.39e-03, 3.24e-03, 9.14e-04, 2.74e-02, 4.08e-04]    []  \n\nBest model at step 1000:\n  train loss: 3.40e-02\n  test loss: 3.84e-02\n  test metric: []\n\n'train' took 16.344045 s\n\nCompiling model...\n'compile' took 36.396567 s\n\nTraining model...\n\nStep      Train loss                                            Test loss                                             Test metric\n1000      [3.97e-03, 3.15e-03, 3.81e-04, 2.63e-02, 1.86e-04]    [6.39e-03, 3.24e-03, 9.14e-04, 2.74e-02, 4.08e-04]    []  \nINFO:tensorflow:Optimization terminated with:\n  Message: CONVERGENCE: REL_REDUCTION_OF_F_&lt;=_FACTR*EPSMCH\n  Objective function value: 0.033171\n  Number of iterations: 5\n  Number of functions evaluations: 65\n1065      [3.14e-03, 3.15e-03, 3.80e-04, 2.63e-02, 1.87e-04]    [5.62e-03, 3.23e-03, 9.08e-04, 2.74e-02, 4.08e-04]    []  \n\nBest model at step 1065:\n  train loss: 3.32e-02\n  test loss: 3.76e-02\n  test metric: []\n\n'train' took 12.395844 s\n\n\n\nEl historial de perdida para el conjunto de entrenamiento es el siguiente:\n\n\nCódigo\nimport plotly.graph_objects as go\n\n# Nombres de las componentes del loss\nloss_labels = [\n    \"PDE residual loss\",\n    \"Initial‐condition loss\",\n    \"Left‐boundary (Dirichlet) loss\",\n    \"Right‐boundary (Neumann) loss\",\n    \"Top/Bottom‐boundary (Neumann) loss\"\n]\n\n# Extraer pasos y pérdida de entrenamiento\nsteps = losshistory.steps\ntrain_loss = np.array(losshistory.loss_train)\n\n# Crear figura\nfig_train = go.Figure()\n\nfor i in range(train_loss.shape[1]):\n    fig_train.add_trace(go.Scatter(\n        x=steps,\n        y=train_loss[:, i],\n        mode='lines',\n        name=loss_labels[i]\n    ))\n\nfig_train.update_layout(\n    title=\"Training Loss history\",\n    xaxis=dict(title=\"Iteration\", tickformat=\".1e\"),\n    yaxis=dict(title=\"Loss\", type=\"log\", tickformat=\".1e\"),\n    template=\"plotly_white\",\n    legend=dict(x=0.99, y=0.99),\n    font=dict(size=14)\n)\nfig_train.show()\n\n\n\n\n\n\n                                                \n\n\nFigura 7.1: Historial de pérdida en el entrenamiento de la red neuronal.\n\n\n\n\nEl historial de perdida para el conjunto de prueba es el siguiente:\n\n\nCódigo\nimport plotly.graph_objects as go\n\n# Nombres de las componentes del loss\nloss_labels = [\n    \"PDE residual loss\",\n    \"Initial‐condition loss\",\n    \"Left‐boundary (Dirichlet) loss\",\n    \"Right‐boundary (Neumann) loss\",\n    \"Top/Bottom‐boundary (Neumann) loss\"\n]\n\n# Extraer pasos y pérdida de entrenamiento\nsteps = losshistory.steps\ntest_loss = np.array(losshistory.loss_test)\n\n# Crear figura\nfig_test = go.Figure()\n\nfor i in range(test_loss.shape[1]):\n    fig_test.add_trace(go.Scatter(\n        x=steps,\n        y=test_loss[:, i],\n        mode='lines',\n        name=loss_labels[i]\n    ))\n\nfig_test.update_layout(\n    title=\"Test Loss history\",\n    xaxis=dict(title=\"Iteration\", tickformat=\".1e\"),\n    yaxis=dict(title=\"Loss\", type=\"log\", tickformat=\".1e\"),\n    template=\"plotly_white\",\n    legend=dict(x=0.99, y=0.99),\n    font=dict(size=14)\n)\nfig_test.show()\n\n\n\n\n\n\n                                                \n\n\nFigura 7.2: Historial de pérdida en el conjunto de prueba de la red neuronal.\n\n\n\n\nA continuación, los valores predichos por la red neuronal a tiempos t(s) de 0.0, 0.25, 0.50, 0.75 y 1.0.\n\n\nCódigo\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\nimport matplotlib.gridspec as gridspec\n\n# Times at which to evaluate the model\ntimes = [0.0, 0.25, 0.5, 0.75, 1.0]\n\n# Generate a grid of (x, y) points\nnum_points = 25\nx = np.linspace(0, 1, num_points)\ny = np.linspace(0, 1, num_points)\nX, Y = np.meshgrid(x, y)\n\n# Create a figure and a GridSpec layout.\n# We reserve one row at the bottom for the colorbar.\nncols = len(times)\nfig = plt.figure(figsize=((5 * ncols) +1, 6))\ngs = gridspec.GridSpec(2, ncols, height_ratios=[10, 1], hspace=0.3)\n\n# Create a list to store the surface plots for the color bar.\nsurf_list = []\n\nfor i, t_val in enumerate(times):\n    # Create trunk input for the model: shape (num_points^2, 3)\n    points = np.vstack((X.flatten(), Y.flatten(), t_val * np.ones_like(X.flatten()))).T\n\n    # Create branch input: for your constant zero initial condition,\n    # just use an array of zeros with shape (1, num_sensors)\n    branch_input = np.zeros((1, sensor_pts.shape[0]))\n\n    # Predict\n    predicted = model.predict((branch_input, points))\n    predicted = predicted.flatten()\n    # Reshape to 2D\n    Z = predicted.reshape(X.shape)\n\n    # 3D subplot\n    ax = fig.add_subplot(gs[0, i], projection=\"3d\")\n\n    # Plot surface\n    surf = ax.plot_surface(\n        Y, X, Z,\n        rstride=1, cstride=1,\n        cmap=\"viridis\",\n        edgecolor=\"none\",\n        antialiased=True\n    )\n    surf_list.append(surf)\n\n    ax.set_title(f\"Time = {t_val:.2f} s\")\n    ax.set_xlabel(\"Y\")\n    ax.set_ylabel(\"X\")\n    ax.set_zlabel(\"T[K]\")\n\n# Create a single color bar below all subplots\n# We take the mappable from the last subplot (or average from one)\ncbar_ax = fig.add_subplot(gs[1, :])\n# Use the mappable from the last subplot; orientation horizontal.\nfig.colorbar(surf_list[-1], cax=cbar_ax, orientation=\"horizontal\")\n\n#plt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nFigura 7.3: Predicciones de la red neuronal a distintos tiempos.\n\n\n\n\n\n\n\n\n\n\n\nFigura 7.4: Resultados reportados por Alessio Borgi (2023) en el caso 2D.\n\n\n\n\n\n\n\n\nAlessio Borgi, Alessandro De Luca, Eugenio Bugli. 2023. «BioHeat PINNs: Temperature Estimation with Bio-Heat Equation using Physics-Informed Neural Networks». https://github.com/alessioborgi/BioHeat_PINNs/tree/main?tab=readme-ov-file#bioheat-pinns-temperature-estimation-with-bio-heat-equation-using-physics-informed-neural-networks.",
    "crumbs": [
      "Estudio de caso",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Predicciones del modelo</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "Referencias",
    "section": "",
    "text": "Alessio Borgi, Alessandro De Luca, Eugenio Bugli. 2023. “BioHeat PINNs: Temperature Estimation with Bio-Heat\nEquation using Physics-Informed Neural Networks.” https://github.com/alessioborgi/BioHeat_PINNs/tree/main?tab=readme-ov-file#bioheat-pinns-temperature-estimation-with-bio-heat-equation-using-physics-informed-neural-networks.\n\n\nBlechschmidt, Jan, and Oliver G. Ernst. 2021. “Three Ways to Solve\nPartial Differential Equations with Neural Networks—a Review.”\nGAMM-Mitteilungen 44 (2): e202100006. https://doi.org/10.1002/gamm.202100006.\n\n\nDutta, Abhijit, and Gopal Rangarajan. 2018. “Diffusion in\nPharmaceutical Systems: Modelling and Applications.” Journal\nof Pharmacy and Pharmacology 70 (5): 581–98. https://doi.org/10.1111/jphp.12885.\n\n\nInstituto Nacional del Cáncer. 2021. “¿Qué es\nel cáncer?” https://www.cancer.gov/espanol/cancer/naturaleza/que-es.\n\n\nKarniadakis, George Em, Ioannis G. Kevrekidis, Lu Lu, Paris Perdikaris,\nSifan Wang, and Liu Yang. 2021. “Physics-Informed Machine\nLearning.” Nature Reviews Physics 3 (6): 422–40. https://doi.org/10.1038/s42254-021-00314-5.\n\n\nKumar, Varun, Somdatta Goswami, Katiana Kontolati, Michael D. Shields,\nand George Em Karniadakis. 2024. “Synergistic Learning with\nMulti-Task DeepONet for Efficient PDE Problem Solving.” arXiv\nPreprint arXiv:2408.02198. https://arxiv.org/abs/2408.02198.\n\n\nLu, Lu, Pengzhan Jin, Guofei Pang, Zhongqiang Zhang, and George Em\nKarniadakis. 2021. “Learning Nonlinear Operators via DeepONet\nBased on the Universal Approximation Theorem of Operators.”\nNature Machine Intelligence 3 (3): 218–29. https://doi.org/10.1038/s42256-021-00302-5.\n\n\nLu, Lu, Xuhui Meng, Zhiping Mao, and George Em Karniadakis. 2021.\n“DeepXDE: A Deep Learning Library for Solving\nDifferential Equations.” SIAM Review 63 (1): 208–28. https://doi.org/10.1137/19M1274067.\n\n\nNational Cancer Institute. 2021. “Hyperthermia to Treat Cancer.” https://www.cancer.gov/about-cancer/treatment/types/hyperthermia.\n\n\nOrganización Mundial de la Salud. 2022.\n“Cáncer.” https://www.who.int/es/news-room/fact-sheets/detail/cancer.\n\n\nPennes, H. H. 1948. “Analysis of Tissue and Arterial Blood\nTemperatures in the Resting Human Forearm.” Journal of\nApplied Physiology 1 (2): 93–122. https://doi.org/10.1152/jappl.1948.1.2.93.\n\n\nQuintero, Luis A., Mauricio Peñuela, Armando Zambrano, and Edwin\nRodríguez. 2017. “Optimización Del Proceso de Preparación de\nSoluciones Madre de Antibióticos En Un Servicio Farmacéutico\nHospitalario.” Revista Cubana de Farmacia 50 (2):\n448–65. https://www.medigraphic.com/cgi-bin/new/resumen.cgi?IDARTICULO=75483.\n\n\nYang, Lihong, Xin Wu, Qian Wan, Jian Kong, Rui Liu, and Xiaoxi Liu.\n2014. “Pharmaceutical Preparation of Antibiotics: A Review on\nFormulation and Technique.” Asian Journal of Pharmaceutical\nSciences 9 (3): 145–53. https://doi.org/10.1016/j.ajps.2014.04.001.",
    "crumbs": [
      "Referencias"
    ]
  }
]