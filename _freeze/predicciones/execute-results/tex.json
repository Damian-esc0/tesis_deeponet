{
  "hash": "ce3e3245d963e44edaaeab78f9a7a92e",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: Predicciones del modelo\nlang: es\nexecute: \n  freeze: auto\n---\n\n::: {style=\"text-align: justify\"}\nConforme se ha referido previamente, se creó el modelo utilizando Deepxde como base. Resulta relevante descatacar que se empleó la versión 1.10.1 de dicha librería. A continuación se presenta el código fuente de la red neuronal\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\nimport deepxde as dde\nimport numpy as np\nimport tensorflow as tf\n\n# ------------------------------------------------------------------------------\n# Constants and Parameters\n# ------------------------------------------------------------------------------\n\n# Backend and seed\ndde.backend.set_default_backend(\"tensorflow.compat.v1\")\ndde.config.set_random_seed(123)\n\n# Physical parameters\nheat_coefficient = 1.0\np = 1050\nc = 3639\nkeff = 5\ntf = 1800\nL0 = 0.05\ncb = 3825\nQ = 0\nTM = 45\nTa = 37\nalpha = p * c / keff\n\n# Dimensionless coefficients\na1 = tf / (alpha * L0**2)\na2 = tf * cb / (p * c)\na3 = (tf * Q) / (p * c * (TM - Ta))\n\n# Domain boundaries\nx_initial, x_boundary = 0.0, 1.0\ny_initial, y_boundary = 0.0, 1.0\nt_initial, t_final = 0.0, 1.0\n\n# Dataset configuration\npts_dom = 10\npts_bc = 20\npts_ic = 60\nnum_test = 25\n\n# Sensor grid and function space\nnum_sensors = 4\nsize_cov_matrix = 40\n\n# Network architecture\nwidth_net = 20\nlen_net = 3\nAF = \"elu\"\nk_initializer = \"Glorot normal\"\n\n# Training parameters\nnum_iterations = 1000\nlearning_rate = 2e-3\ndecay_rate = 0.05\ndecay_steps = 1000\n\n# ------------------------------------------------------------------------------\n# Geometry and Time Domain\n# ------------------------------------------------------------------------------\n\nspatial_domain = dde.geometry.Rectangle([x_initial, y_initial],\n                                        [x_boundary, y_boundary])\ntime_domain = dde.geometry.TimeDomain(t_initial, t_final)\ngeomtime = dde.geometry.GeometryXTime(spatial_domain, time_domain)\n\n# ------------------------------------------------------------------------------\n# PDE and Conditions\n# ------------------------------------------------------------------------------\n\ndef initial_condition(X):\n    return 0\n\ndef heat_equation(func, u, coords):\n    u_t = dde.grad.jacobian(u, func, i=0, j=2)\n    u_xx = dde.grad.hessian(u, func, i=0, j=0)\n    u_yy = dde.grad.hessian(u, func, i=1, j=1)\n    return a1 * u_t - (u_xx + u_yy) + a2 * u\n\ndef zero_value(X):\n    return 0\n\ndef time_value(X):\n    return X[:, 2]\n\ndef is_on_vertex(x):\n    vertices = np.array([[x_initial, y_initial],\n                         [x_boundary, y_initial],\n                         [x_initial, y_boundary],\n                         [x_boundary, y_boundary]])\n    return any(np.allclose(x, v) for v in vertices)\n\ndef is_initial(X, on_initial):\n    return on_initial and np.isclose(X[2], t_initial)\n\ndef left_boundary(X, on_boundary):\n    spatial = X[0:2]\n    t = X[2]\n    return (\n        on_boundary \n        and np.isclose(spatial[0], x_initial) \n        and not np.isclose(t, t_initial) \n        and not is_on_vertex(spatial)\n    )\n\ndef right_boundary(X, on_boundary):\n    spatial = X[0:2]\n    t = X[2]\n    return (\n        on_boundary \n        and np.isclose(spatial[0], x_boundary) \n        and not np.isclose(t, t_initial) \n        and not is_on_vertex(spatial)\n    )\n\ndef up_low_boundary(X, on_boundary):\n    spatial = X[0:2]\n    t = X[2]\n    return (on_boundary \n    and (np.isclose(spatial[1], y_initial) \n    or np.isclose(spatial[1], y_boundary)) \n    and not np.isclose(t, t_initial) \n    and not is_on_vertex(spatial)\n    )\n\n# Initial and boundary conditions\nic = dde.icbc.IC(geomtime, initial_condition, is_initial)\nleft_bc = dde.icbc.DirichletBC(geomtime, \n                                zero_value, left_boundary)\nright_bc = dde.icbc.NeumannBC(geomtime,\n                                time_value, right_boundary)\nup_low_bc = dde.icbc.NeumannBC(geomtime, \n                                zero_value, up_low_boundary)\n\n# ------------------------------------------------------------------------------\n# Dataset Construction\n# ------------------------------------------------------------------------------\n\npde_data = dde.data.TimePDE(\n    geomtime,\n    heat_equation,\n    [ic, left_bc, right_bc, up_low_bc],\n    num_domain=pts_dom,\n    num_boundary=pts_bc,\n    num_initial=pts_ic \n)\n\n# ------------------------------------------------------------------------------\n# Sensor Points and Function Space\n# ------------------------------------------------------------------------------\n\nside = np.linspace(x_initial, x_boundary, num_sensors + 1)\nx, y = np.meshgrid(side, side, indexing='xy')\nsensor_pts = np.stack([x.ravel(), y.ravel()], axis=1)\n\nfs = dde.data.function_spaces.GRF2D(N=size_cov_matrix, \n                                    interp=\"linear\")\n\ndata = dde.data.PDEOperatorCartesianProd(\n    pde_data,\n    fs,\n    sensor_pts,\n    num_function=(num_sensors + 1)**2,\n    function_variables=[0, 1],\n    num_test=num_test\n)\n\n# ------------------------------------------------------------------------------\n# Network Definition\n# ------------------------------------------------------------------------------\n\nbranch_layers = [(num_sensors + 1)**2] + len_net * [width_net]\ntrunk_layers = [3] + len_net * [width_net]\n\nnet = dde.nn.DeepONetCartesianProd(\n    branch_layers,\n    trunk_layers,\n    activation=AF,\n    kernel_initializer=k_initializer\n)\n\n# ------------------------------------------------------------------------------\n# Model Compilation and Training\n# ------------------------------------------------------------------------------\n\nmodel = dde.Model(data, net)\nmodel.compile(\"adam\", lr=learning_rate, decay=(\"inverse time\", decay_steps, decay_rate))\nlosshistory, train_state = model.train(iterations=num_iterations)\n\n# Fine-tuning with LBFGS optimizer\nmodel.compile(\"L-BFGS\")\nlosshistory, train_state = model.train()\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n2025-05-20 19:13:11.966121: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n2025-05-20 19:13:12.015891: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n2025-05-20 19:13:12.016611: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\nTo enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2025-05-20 19:13:12.774304: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\nUsing backend: tensorflow.compat.v1\nOther supported backends: tensorflow, pytorch, jax, paddle.\npaddle supports more examples now and is recommended.\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nWARNING:tensorflow:From /home/damian/.local/lib/python3.8/site-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\nInstructions for updating:\nnon-resource variables are not supported in the long term\nSetting the default backend to \"tensorflow.compat.v1\". You can change it in the ~/.deepxde/config.json file or export the DDE_BACKEND environment variable. Valid options are: tensorflow.compat.v1, tensorflow, pytorch, jax, paddle (all lowercase)\nCompiling model...\nBuilding DeepONetCartesianProd...\n'build' took 0.087113 s\n\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n/home/damian/.local/lib/python3.8/site-packages/deepxde/nn/tensorflow_compat_v1/deeponet.py:549: UserWarning:\n\n`tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n\n/home/damian/.local/lib/python3.8/site-packages/deepxde/nn/tensorflow_compat_v1/deeponet.py:556: UserWarning:\n\n`tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n\n/home/damian/.local/lib/python3.8/site-packages/deepxde/nn/tensorflow_compat_v1/deeponet.py:570: UserWarning:\n\n`tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n'compile' took 14.870243 s\n\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n2025-05-20 19:13:29.177209: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:375] MLIR V1 optimization pass is not enabled\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nTraining model...\n\nStep      Train loss                                            Test loss                                             Test metric\n0         [2.57e+00, 4.03e-01, 4.13e-01, 6.71e-01, 1.05e+00]    [1.57e+00, 1.57e-01, 3.45e-01, 5.19e-01, 3.07e-01]    []  \n1000      [3.97e-03, 3.15e-03, 3.81e-04, 2.63e-02, 1.86e-04]    [6.39e-03, 3.24e-03, 9.14e-04, 2.74e-02, 4.08e-04]    []  \n\nBest model at step 1000:\n  train loss: 3.40e-02\n  test loss: 3.84e-02\n  test metric: []\n\n'train' took 15.590192 s\n\nCompiling model...\n'compile' took 33.016664 s\n\nTraining model...\n\nStep      Train loss                                            Test loss                                             Test metric\n1000      [3.97e-03, 3.15e-03, 3.81e-04, 2.63e-02, 1.86e-04]    [6.39e-03, 3.24e-03, 9.14e-04, 2.74e-02, 4.08e-04]    []  \nINFO:tensorflow:Optimization terminated with:\n  Message: CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH\n  Objective function value: 0.033171\n  Number of iterations: 5\n  Number of functions evaluations: 65\n1065      [3.14e-03, 3.15e-03, 3.80e-04, 2.63e-02, 1.87e-04]    [5.62e-03, 3.23e-03, 9.08e-04, 2.74e-02, 4.08e-04]    []  \n\nBest model at step 1065:\n  train loss: 3.32e-02\n  test loss: 3.76e-02\n  test metric: []\n\n'train' took 11.204808 s\n\n```\n:::\n:::\n\n\nEl historial de perdida para el conjunto de entrenamiento es el siguiente:\n\n::: {.cell execution_count=2}\n``` {.python .cell-code}\nimport plotly.graph_objects as go\n\n# Nombres de las componentes del loss\nloss_labels = [\n    \"PDE residual loss\",\n    \"Initial‐condition loss\",\n    \"Left‐boundary (Dirichlet) loss\",\n    \"Right‐boundary (Neumann) loss\",\n    \"Top/Bottom‐boundary (Neumann) loss\"\n]\n\n# Extraer pasos y pérdida de entrenamiento\nsteps = losshistory.steps\ntrain_loss = np.array(losshistory.loss_train)\n\n# Crear figura\nfig_train = go.Figure()\n\nfor i in range(train_loss.shape[1]):\n    fig_train.add_trace(go.Scatter(\n        x=steps,\n        y=train_loss[:, i],\n        mode='lines',\n        name=loss_labels[i]\n    ))\n\nfig_train.update_layout(\n    title=\"Training Loss history\",\n    xaxis=dict(title=\"Iteration\", tickformat=\".1e\"),\n    yaxis=dict(title=\"Loss\", type=\"log\", tickformat=\".1e\"),\n    template=\"plotly_white\",\n    legend=dict(x=0.99, y=0.99),\n    font=dict(size=14)\n)\nfig_train.show()\n```\n:::\n\n\n::: {.content-visible when-format=\"html\"}\n\n::: {.cell execution_count=3}\n\n::: {#fig-training_loss .cell-output .cell-output-display}\n```\nUnable to display output for mime type(s): text/html\n```\n\nHistorial de pérdida en el entrenamiento de la red neuronal.\n:::\n:::\n\n\n:::\n\n::: {.content-visible when-format=\"pdf\"}\n\n\n![Gráfica de la perdida en el entrenamiento.](images/fig-training_loss.png){#fig-loss_training fig-align=\"center\"}\n:::\n\n\n\nEl historial de perdida para el conjunto de prueba es el siguiente:\n\n::: {.cell execution_count=5}\n``` {.python .cell-code}\nimport plotly.graph_objects as go\n\n# Nombres de las componentes del loss\nloss_labels = [\n    \"PDE residual loss\",\n    \"Initial‐condition loss\",\n    \"Left‐boundary (Dirichlet) loss\",\n    \"Right‐boundary (Neumann) loss\",\n    \"Top/Bottom‐boundary (Neumann) loss\"\n]\n\n# Extraer pasos y pérdida de entrenamiento\nsteps = losshistory.steps\ntest_loss = np.array(losshistory.loss_test)\n\n# Crear figura\nfig_test = go.Figure()\n\nfor i in range(test_loss.shape[1]):\n    fig_test.add_trace(go.Scatter(\n        x=steps,\n        y=test_loss[:, i],\n        mode='lines',\n        name=loss_labels[i]\n    ))\n\nfig_test.update_layout(\n    title=\"Test Loss history\",\n    xaxis=dict(title=\"Iteration\", tickformat=\".1e\"),\n    yaxis=dict(title=\"Loss\", type=\"log\", tickformat=\".1e\"),\n    template=\"plotly_white\",\n    legend=dict(x=0.99, y=0.99),\n    font=dict(size=14)\n)\nfig_test.show()\n```\n:::\n\n\n::: {.content-visible when-format=\"html\"}\n\n::: {.cell execution_count=6}\n\n::: {#fig-test_loss .cell-output .cell-output-display}\n```\nUnable to display output for mime type(s): text/html\n```\n\nHistorial de pérdida en el conjunto de prueba de la red neuronal.\n:::\n:::\n\n\n:::\n\n::: {.content-visible when-format=\"pdf\"}\n\n\n![Gráfica de la perdida en el conjunto de prueba.](images/fig-test_loss.png){#fig-loss_test fig-align=\"center\"}\n:::\n\nA continuación, los valores predichos por la red neuronal a tiempos t(s) de 0.0, 0.25, 0.50, 0.75 y 1.0. \n\n::: {.cell execution_count=8}\n``` {.python .cell-code}\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\nimport matplotlib.gridspec as gridspec\n\n# Times at which to evaluate the model\ntimes = [0.0, 0.25, 0.5, 0.75, 1.0]\n\n# Generate a grid of (x, y) points\nnum_points = 25\nx = np.linspace(0, 1, num_points)\ny = np.linspace(0, 1, num_points)\nX, Y = np.meshgrid(x, y)\n\n# Create a figure and a GridSpec layout.\n# We reserve one row at the bottom for the colorbar.\nncols = len(times)\nfig = plt.figure(figsize=((5 * ncols) +1, 6))\ngs = gridspec.GridSpec(2, ncols, height_ratios=[10, 1], hspace=0.3)\n\n# Create a list to store the surface plots for the color bar.\nsurf_list = []\n\nfor i, t_val in enumerate(times):\n    # Create trunk input for the model: shape (num_points^2, 3)\n    points = np.vstack((X.flatten(), Y.flatten(), t_val * np.ones_like(X.flatten()))).T\n\n    # Create branch input: for your constant zero initial condition,\n    # just use an array of zeros with shape (1, num_sensors)\n    branch_input = np.zeros((1, sensor_pts.shape[0]))\n\n    # Predict\n    predicted = model.predict((branch_input, points))\n    predicted = predicted.flatten()\n    # Reshape to 2D\n    Z = predicted.reshape(X.shape)\n\n    # 3D subplot\n    ax = fig.add_subplot(gs[0, i], projection=\"3d\")\n\n    # Plot surface\n    surf = ax.plot_surface(\n        Y, X, Z,\n        rstride=1, cstride=1,\n        cmap=\"viridis\",\n        edgecolor=\"none\",\n        antialiased=True\n    )\n    surf_list.append(surf)\n\n    ax.set_title(f\"Time = {t_val:.2f} s\")\n    ax.set_xlabel(\"Y\")\n    ax.set_ylabel(\"X\")\n    ax.set_zlabel(\"T[K]\")\n\n# Create a single color bar below all subplots\n# We take the mappable from the last subplot (or average from one)\ncbar_ax = fig.add_subplot(gs[1, :])\n# Use the mappable from the last subplot; orientation horizontal.\nfig.colorbar(surf_list[-1], cax=cbar_ax, orientation=\"horizontal\")\n\n#plt.tight_layout()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![Predicciones de la red neuronal a distintos tiempos.](predicciones_files/figure-pdf/fig-my_results-output-1.pdf){#fig-my_results fig-pos='H'}\n:::\n:::\n\n\n![Resultados reportados por @medical_rep en el caso 2D.](images/results_paper.png){#fig-results_fnn fig-align=\"center\" width=\"750\"}\n:::\n\n",
    "supporting": [
      "predicciones_files/figure-pdf"
    ],
    "filters": []
  }
}