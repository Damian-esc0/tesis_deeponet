{
  "hash": "10c60de51aa4bfa9edb3bf6939f75754",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: DeepONet\nlang: es\nexecute: \n  freeze: auto\n---\n\n::: {style=\"text-align: justify\"}\n**DeepONet** (Deep Operator Network) es una arquitectura de red neuronal profunda diseñada para aprender operadores no lineales que mapean funciones de entrada a funciones de salida. A diferencia de las redes convencionales que aprenden funciones escalares, DeepONet se enfoca en representar operadores completos, como soluciones de ecuaciones diferenciales, a partir de datos observados o simulaciones numérica [@lu2021deeponet].\n\n\n## Arquitectura\nLa arquitectura de DeepONet está compuesta por dos redes principales: la red de *branch* y la red de *trunk*. La red *branch* procesa las evaluaciones discretas de la función de entrada (por ejemplo, condiciones iniciales o de frontera), mientras que la red *trunk* recibe como entrada los puntos del dominio donde se desea evaluar la función de salida. La salida final se obtiene mediante el producto punto de los vectores generados por ambas redes, lo que permite representar operadores complejos con alta generalización a nuevos datos [@lu2021deeponet].\n\n![**Ilustraciones del planteamiento del problema y arquitectura DeepONet que conducen a una buena generalización. a)** Para que la red aprenda un operador $G : u \\rightarrow G(u)$ se necesitan dos entradas $[u(x_1), u(x_2), ..., u(x_m)]$ e $y$. **b)** Ilustración de los datos de entrenamiento. Para cada función de entrada $u$, se requiere el mismo número de evaluaciones en los mismos sensores dispersos $x_1, x_2, ..., x_m$. Sin embargo, no se impone ninguna restricción sobre el número ni las ubicaciones para la evaluación de las funciones de salida. **c)** La DeepONet *stacked* se inspira en el **Teorema de aproximación universal para operadores** y consta de una red *Trunk* y $p$ redes *Branch* apiladas. La red cuya construcción se inspira en el mismo teorema es una DeepONet *stacked* formada al elegir la red *Trunk* como una red de una capa de ancho $p$ y cada red *Branch* como una red de una capa oculta de ancho $n$. **d)** La red DeepONet *unstacked* se inspira en el **Teorema general de aproximación universal para operadores** y consta de una red *Trunk* y una red *Branch*. Una red DeepONet *unstacked* puede considerarse como una red DeepONet *stacked*, en la que todas las redes *Branch* comparten el mismo conjunto de parámetros [@lu2021deeponet].](images/deeponet_architecture.png){#fig-deeponet-arch fig-align=\"center\" width=\"600\"}\n\n## Ejemplo de resolución de un operador usando DeepONet\nSe resolverá el operador\n$$\nG: f\\rightarrow u\n$$\n\npara el problema unidemensional de Poisson:\n$$\nu''(x) = f(x), \\quad x\\in[0,1]\n$$\n\ncon la condición de frontera de Dirichlet\n$$\nu(0)=u(1)=0\n$$\n\nel término $f$ representa a una función continua arbitraria.\n\n::: {#796882cb .cell execution_count=1}\n``` {.python .cell-code}\nimport deepxde as dde\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n\n# Poisson equation: -u_xx = f\ndef equation(x, y, f):\n    dy_xx = dde.grad.hessian(y, x)\n    return -dy_xx - f\n\n# Domain is interval [0, 1]\ngeom = dde.geometry.Interval(0, 1)\n\n# Zero Dirichlet BC\ndef u_boundary(_):\n    return 0\n\ndef boundary(_, on_boundary):\n    return on_boundary\n\nbc = dde.icbc.DirichletBC(geom, u_boundary, boundary)\n\n# Define PDE\npde = dde.data.PDE(geom, equation, bc, num_domain=100, num_boundary=2)\n\n# Function space for f(x) are polynomials\ndegree = 3\nspace = dde.data.PowerSeries(N=degree + 1)\n\n# Choose evaluation points\nnum_eval_points = 10\nevaluation_points = geom.uniform_points(num_eval_points, boundary=True)\n\n# Define PDE operator\npde_op = dde.data.PDEOperatorCartesianProd(\n    pde,\n    space,\n    evaluation_points,\n    num_function=100,\n    num_test=20\n)\n\n# Setup DeepONet\ndim_x = 1\np = 32\nnet = dde.nn.DeepONetCartesianProd(\n    [num_eval_points, 32, p],\n    [dim_x, 32, p],\n    activation=\"tanh\",\n    kernel_initializer=\"Glorot normal\",\n)\n\n# Define and train model\nmodel = dde.Model(pde_op, net)\ndde.optimizers.set_LBFGS_options(maxiter=1000)\nmodel.compile(\"L-BFGS\")\nmodel.train()\n\n# Plot realisations of f(x)\nn = 3\nfeatures = space.random(n)\nfx = space.eval_batch(features, evaluation_points)\n\nx = geom.uniform_points(100, boundary=True)\ny = model.predict((fx, x))\n```\n:::\n\n\n::: {#54798828 .cell execution_count=2}\n``` {.python .cell-code}\n# Setup figure\nfig = plt.figure(figsize=(7, 8))\nplt.subplot(2, 1, 1)\nplt.title(\"Ecuación de Poisson: término f(x) y solución u(x)\")\nplt.ylabel(\"f(x)\")\nz = np.zeros_like(x)\nplt.plot(x, z, \"k-\", alpha=0.1)\n\n# Plot source term f(x)\nfor i in range(n):\n    plt.plot(evaluation_points, fx[i], \"--\")\n\n# Plot solution u(x)\nplt.subplot(2, 1, 2)\nplt.ylabel(\"u(x)\")\nplt.plot(x, z, \"k-\", alpha=0.1)\nfor i in range(n):\n    plt.plot(x, y[i], \"-\")\nplt.xlabel(\"x\")\n\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![Resultados de la red DeepONet](deeponet_files/figure-html/cell-3-output-1.png){width=617 height=672}\n:::\n:::\n\n\n## Comparación con una PINN\nEn contraste con una red PINN convencional (Physics-Informed Neural Network), que resuelve una instancia específica de una ecuación diferencial para un conjunto dado de condiciones, DeepONet aprende el operador general que resuelve muchas instancias a la vez. Mientras que una PINN debe ser reentrenada para cada nuevo problema, DeepONet, una vez entrenado, puede predecir soluciones rápidamente para múltiples condiciones nuevas. Esto lo hace especialmente eficiente en aplicaciones donde se requiere realizar inferencias repetidas, como en control o diseño inverso [@kumar2024deeponet].\n\n\n\n\n\n:::\n\n",
    "supporting": [
      "deeponet_files/figure-html"
    ],
    "filters": [],
    "includes": {}
  }
}